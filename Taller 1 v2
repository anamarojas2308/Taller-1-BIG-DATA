---
  title: "Taller_1_BDML"
authors: "Julian Delgado Gutierrez, Ana María Rojas, Juan David Rincón, Mario Andrés Mercado"
date: "2025-02-19"
output: html_document
editor_options: 
  markdown: 
  wrap: 72
---

  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem Set 1: Predicting Income

## Introduction

In the public sector, accurate reporting of individual income is
critical for computing taxes. However, tax fraud of all kinds has always
been a significant issue. According to the Internal Revenue Service
(IRS), about 83.6% of taxes are paid voluntarily and on time in the
US.1. One of the causes of this gap is the under-reporting of incomes by
individuals. An income predicting model could potentially assist in
flagging cases of fraud that could lead to the reduction of the gap.
Furthermore, an income prediction model can help identify vulnerable
individuals and families that may need further assistance.

The objective of the problem set is to apply the concepts we learned
using “real” world data. For that, we are going to scrape from the
following website:
  <https://ignaciomsarmiento.github.io/GEIH2018-sample/> This website
contains data for Bogotá from the 2018 “Medición de Pobreza Monetaria
y Desigualdad Report” that takes information from the
[GEIH.](https://www.dane.gov.co/index.php/estadisticas-por-tema/mercado-laboral/empleo-y-desempleo/geih-historicos)

### General Instructions

The main objective is to construct a model of individual hourly wages

$$w = f(X)+u$$
  
  where $w$ is the hourly wage, and $X$ is a matrix that includes
potential explanatory variables/predictors. In this problem set, we will
focus on $f(X) = X\beta$. The final document, in .pdf format, must
contain the following sections:
  
  1.  *Introduction.* The introduction briefly states the problem and if there are any antecedents. It briefly describes the data and its suitability to address the problem set question. It contains a preview of the results and main takeaways.

2. *Data.* We will use data for Bogot´a from the 2018 “Medición de Pobreza Monetaria y Desigualdad Report” that takes information from the GEIH.

The data set contains all individuals sampled in Bogota and is available at the following website <https://ignaciomsarmiento.github.io/GEIH2018-sample/>. To obtain
the data, you must scrape the website.

In this problem set, we will focus only on employed individuals older than eighteen (18) years old. Restrict the data to these individuals and perform a descriptive analysis of the variables used in the problem set. Keep in mind that in the data, there are many observations with missing data or 0 wages. I leave it to you to find a way to handle this data

When writing this section up, you must:
  
  (a) Describe the data briefly, including its purpose, and any other relevant information.
(b) Describe the process of acquiring the data and if there are any restrictions to accessing/scraping these data.
(c) Describe the data cleaning process and
(d) Descriptive the variables included in your analysis. At a minimum, you should include a descriptive statistics table with its interpretation. However, I expect a deep analysis that helps the reader understand the data, its variation, and the justification for your data choices. Use your professional knowledge to add value to this section. Do not present it as a “dry” list of ingredients.

3. *Age-wage profile.*  A great deal of evidence in *labor economics* suggests that the typical worker’s age-wage profile has a predictable path: *“Wages tend to be low when the worker is young; they rise as the worker ages, peaking at about age 50; and the wage rate tends to remain stable or decline slightly after age 50”.*
  
  In this subsection we are going to estimate the Age-wage profile profile for the individuals in this sample:
  
  
  $$log(w) = \beta_{1} + \beta_{2}Age + \beta_{3} Age^{2} + u$$
  When presenting and discussing your results, include:
  
  - A regression table.
- An interpretation of the coefficients and it’s significance.
- A discussion of the model’s in sample fit.
- A plot of the estimated age-earnings profile implied by the above equation. Including a discussion of the “peak age” with it’s respective confidence intervals. (Note: Use bootstrap to construct the confidence intervals.)

4. *The gender earnings GAP.* Policymakers have long been concerned with the gender wage gap, and is going to be our focus in this subsection.

(a) Begin by estimating and discussing the unconditional wage gap:
  
  $$log(w) = \beta_{1} + \beta_{2}Female + u$$
  where *Female* is an indicator that takes one if the individual in the sample is
identified as female.

(b) *Equal Pay for Equal Work?* A common slogan is“equal pay for equal work”. One way to interpret this is that for employees with similar worker and job characteristics, no gender wage gap should exist. Estimate a conditional earnings gap incorporating control variables such as similar worker and job characteristics.
In this section, estimate the conditional wage gap:
  
  - First, using FWL
- Second, using FWL with bootstrap. Compare the estimates and the standard errors.

(c) Next, plot the predicted age-wage profile and estimate the implied “peak ages” with the respective confidence intervals by gender

When presenting and discussing your results, include:
  
  - An estimating equation, explaining the included control variables *(beware of “bad controls”).*
  - A regression table, with the estimates side by side of the conditional and unconditional wage gaps, highlighting the coefficient of interest. Controls, should
not be included in the table but dutifully noted.
- An interpretation of the“Female” coefficients, a comparison between the models, and the in-sample fit.
- A discussion about the implied peak ages and their statistical similarity/difference.
- A thoughtful discussion about the unconditional and conditional wage gap, seeking to answer if the changes in the coefficient are evidence of a selection problem, a ”discrimination problem,” a mix, or none of these issues.


5. *Predicting earnings.* In the previous sections, you estimated some specifications with
inference in mind. In this subsection, we will evaluate the predictive power of these
specifications.

(a) Split the sample into two: a training (70%) and a testing (30%) sample. (Don’t forget to set a seed to achieve reproducibility. In R, for example you can use set.seed(10101), where 10101 is the seed.)

(b) Report and compare the predictive performance in terms of the RMSE of all
the previous specifications with at least five (5) additional specifications that
explore non-linearities and complexity.

(c) In your discussion of the results, comment:
  
  - About the overall performance of the models.
- About the specification with the lowest prediction error.
- For the specification with the lowest prediction error, explore those observations that seem to ”miss the mark.” To do so, compute the prediction errors
in the test sample, and examine its distribution. Are there any observations
in the tails of the prediction error distribution? Are these outliers potential
people that the DIAN should look into, or are they just the product of a
flawed model?
  
  (d) LOOCV. For the two models with the lowest predictive error in the previous section, calculate the predictive error using Leave-one-out-cross-validation
(LOOCV). Compare the results of the test error with those obtained with the
validation set approach and explore the potential links with the influence statistic. (Note: when attempting this subsection, the calculati
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
                                                                                       
# Configuración Inicial

```{r setup, include=FALSE}
rm(list = ls())
gc()
closeAllConnections()

# Cargar librerías necesarias
load.lib <- c('data.table', 'dplyr', 'ggplot2', 'stargazer', 'tidyverse', 'lubridate',
'plotly', 'rvest', 'tm', 'wordcloud', 'caret', 'boot', 'pacman')

install.lib <- load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib)
sapply(load.lib, require, character = TRUE)

print("Librerías cargadas correctamente")
```

PUNTO 2: \# Web Scraping de GEIH

```{r scraping, include=FALSE}
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
pagina <- read_html(paste0(url_base, "1.html"))
datos_totales <- pagina %>% html_table(fill = TRUE) %>% .[[1]]

for (i in 2:10) {
url <- paste0(url_base, i, ".html")
tryCatch({
pagina <- read_html(url)
tabla <- pagina %>% html_table(fill = TRUE) %>% .[[1]]
datos_totales <- bind_rows(datos_totales, tabla)
}, error = function(e) {
message(paste("Error al cargar la página", i, ":", e))
})
}

head(datos_totales)
```

#PUNTO 2A: #Describir brevemente la data: #Una vez se combinan los datos
y se obtiene la base completa, se evidencia que hay información que nos
permite analizar el mercado laboral y variables ecónomicas de diferentes
individios. Se encuentra que el objetivo principal de la base de datos
es analizar ingresos (salario) y comportamientos del mercado. Hay
variables que nos permiten analizar características individuales como la
edad, género, educación, departamento, entre otras y variables que se
relacionan con la actividad laboral como los ingresos, horas trabajadas,
tipo de empleo, sector económico, entre otras. La selección de las
variables es clave puesto que permitirá evaluar los factores que
influyen en el ingreso y analizar fenómenos como la brecha salarial de
género. De igual forma, es importante mencionar que la base tiene
valores faltantes y observaciones con ingreso igual a cero, lo que
sugiere la necesidad de un proceso de limpieza antes del análisis. La
base tiene una estructura de formato tabular, la cual facilita el
procesamiento de los datos y el análisis de los mismos mediante
descripciones estadísticas. Adicionalmente, se considera que los datos
proporcionados son fundamentales para construir un modelo predictivo de
ingresos por hora y detectar como variables sociodemográficas y
laborales inciden en la remuneración de los individuos.

#PUNTO 2B: #Proceso y dificultades accediendo a la data: #En primer
lugar hay que tener presente que los datos no se pueden descargar como
un archivo, sino que se encuentran en un página web
(<https://ignaciomsarmiento.github.io/GEIH2018_sample/>), por lo cual,
es necesario hacer web scrapping para extraerlos. Los datos estaban
distribuidos en diferentes sitios web, por lo se combinaron en un único
conjunto de datos. De esta forma, se difinió la base de la URL, donde
cada página se nombró siguiendo un patrón (geih_page_1.html",
"geih_page_2.html ..., etc). Con ayuda de la libreria rvest se leyó el
contenido HTML de cada página (data chunk 1:10), se extrajeron las
tablas y se combinaron los datos en un solo dataframe, almacenando el
resultado en la variables datos_totales. Para evitar que el código fuese
a generar error en caso de que una de las páginas no cargara
correctamente, se utilizó tryCatch (manejo de errores). De esta forma,
se buscaba que si las páginas cargaban correctamente, se extrayera las
tablas y se añadieran a la variable "datos_totales" y si se llegaba a
presentar algún problema de lectura, se captaría el error sin detener la
ejecución total. Por lo tanto, el código permite automatizar el proceso
de recolección de datos que están distribuidores en diferentes sitios
web y cuando se trabaja con grandes volúmenes de datos, aún si se
presenta algún problema. No se encuentran restricciones dado que la
página no tiene capchas ni bloqueos para la extracción de datos, pero
tuvimos presente no hacer múltiples solicitudes en un corto período de
tiempo para no sobrecargar el servidor. Por el otro lado, los datos son
públicos y fueron diseñados para fines académicos, por lo que facilito
en gran medida el scrapping.

# Renombrar Columnas y Limpiar Datos

```{r limpieza, include=FALSE}
datos_totales <- datos_totales %>%
  rename(ingreso_total = ingtot,
         edad = age,
         hombre = sex,
         T_horas_trabajadas = totalHoursWorked,
         Salario_hora = y_salary_m_hu
  ) %>%
  mutate(
    ln_Salario_hora = log(Salario_hora)
  )

# Filtrar registros inválidos 

datos_filtrados <- datos_totales %>%
  filter(edad > 18, ingreso_total > 0, T_horas_trabajadas > 0, Salario_hora > 0)

# Identificar y eliminar outliers usando percentiles 1% y 99%
low_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.01)
up_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.99)
low_salary <- quantile(datos_filtrados$Salario_hora, 0.01)
up_salary <- quantile(datos_filtrados$Salario_hora, 0.99)

datos_filtrados <- datos_filtrados %>%
  filter(T_horas_trabajadas >= low_hours & T_horas_trabajadas <= up_hours,
         Salario_hora >= low_salary & Salario_hora <= up_salary)

```

```{r dividir_datos, include=FALSE}
# Seleccionar unicamente la variable de Salario Hora, no ingresos
numericas <- datos_filtrados %>% select(-all_of(c("y_ingLab_m_ha", "y_total_m_ha", "p6500", "y_salary_m", "impa", "y_ingLab_m", "y_total_m", "ingtotob", "ingreso_total")))

# Seleccionar las columnas numéricas del dataframe
numericas <- numericas[, sapply(numericas, is.numeric)]

# Filtrar las columnas con desviación estándar diferente a cero y sin valores NA
numericas_filtradas <- numericas[, sapply(numericas, function(x) {
  !all(is.na(x)) && sd(x, na.rm = TRUE) != 0
})]

# Ver el resumen de las columnas filtradas
summary(numericas_filtradas)

# Calcular la correlación de cada variable con 'ingreso_total'
correlaciones_con_y <- sapply(numericas_filtradas, function(x) cor(x, numericas$Salario_hora, use = "complete.obs"))

# Crear el dataframe con las correlaciones
resultados_correlacion <- data.frame(Variable = names(correlaciones_con_y), Correlacion_con_y = correlaciones_con_y)

# Mostrar los resultados
print(resultados_correlacion)

# Compute the absolute value of the correlations with 'Salario_hora'
correlaciones_abs <- abs(correlaciones_con_y)

# Sort the correlations in descending order
correlaciones_abs_sorted <- sort(correlaciones_abs, decreasing = TRUE)
print(correlaciones_abs_sorted)

# Select the names of the top 25 variables with the highest correlation
top_25_vars <- names(correlaciones_abs_sorted)[1:25]

# Create a new dataframe with the top 25 variables and their corresponding correlations
top_25_correlaciones <- data.frame(Variable = top_25_vars,
                                   Correlacion_con_y = correlaciones_abs_sorted[1:25])

# Print the results
print(top_25_correlaciones)

```

# Punto 2C: The data cleaning process involves web scraping labor market data from multiple web pages using the rvest package, combining the extracted tables into a single dataset while handling errors with tryCatch to prevent interruptions. The dataset, which focuses on analyzing wages and labor market behaviors, is then cleaned by renaming key columns (e.g., age, gender, salary per hour) and creating a new logarithmic salary variable. Invalid records are filtered out by excluding individuals under 18, those with zero or negative income, and those who did not work any hours. Outliers in working hours and hourly wages are removed based on the 1st and 99th percentiles. Further, only numeric columns are selected, and variables with zero standard deviation or excessive missing values (over 90%) are dropped. Correlations between the remaining variables and hourly salary are computed, and the top 25 most correlated features are identified. A final dataset is created by selecting relevant socio-demographic and labor-related variables. Visualizations are used to inspect missing values, and variables with a high proportion of missing data are excluded to maintain data quality. This cleaned dataset is ready for further statistical analysis and predictive modeling.


```{r dividir_datos, include=FALSE}
# Seleccionar variables importantes para el modelo 

variables_seleccionadas <- c("edad", "clase", "hombre", "college", "depto", "maxEducLevel", "ocu", "dsi", "informal", "formal", "cuentaPropia", "microEmpresa", "Salario_hora", "ingtotes", "impa", "isa", "p6500", "p6510", "p6580", "p6750", "p7070", "cotPension", "p6920", "hoursWorkUsual", "hoursWorkActualSecondJob", "fex_c", "fweight", "oficio", "estrato1", "ln_Salario_hora")

base_seleccionada <- datos_filtrados %>% select(all_of(variables_seleccionadas))

```
```{r dividir_datos, include=FALSE}
skim(base_seleccionada) 

miss_values <- skim(base_seleccionada) %>% select( skim_variable, n_missing)
Nobs <- nrow(base_seleccionada) 
# percentage of missing
miss_values <- miss_values %>% mutate(p_missing= n_missing/Nobs)
miss_values <- miss_values %>% arrange(-n_missing)

ggplot(miss_values, aes(x = reorder(skim_variable, +p_missing) , y =  p_missing)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(title = "N Missing Per Variable", x = "Var Name", y = "Missings")+ 
  theme(axis.text = element_text(size = 5)) 

# Borrar aquellas variables con más del 90% de missing values ya que imputarlas puede traer más ruido que otra cosa
var_miss <- miss_values %>% filter (p_missing > 0.9)
base_seleccionada <- base_seleccionada %>% select(-all_of(var_miss[[1]]))
```

```{r dividir_datos, include=FALSE}
# Loop through each column and display descriptive statistics
for (col_name in colnames(base_seleccionada)) {
  cat("Descriptive statistics for", col_name, ":\n")
  print(summary(base_seleccionada[[col_name]]))
  skim(base_seleccionada[[col_name]])
  cat("\n")
}

```

```{r dividir_datos, include=FALSE}
# Usar cut para crear los grupos de edad
base_seleccionada$grupo_edad <- cut(base_seleccionada$edad, 
                                    breaks = c(-Inf, 20, 30, 40, 50, 60, 70, Inf), 
                                    labels = c("<20", "20-30", "30-40", "40-50", "50-60", "60-70", ">70"),
                                    right = FALSE)

base_seleccionada$hombre <- as.factor(base_seleccionada$hombre)

# Calcular el promedio de ingresos por grupo de edad y género
promedio_ingresos <- base_seleccionada %>%
  group_by(grupo_edad, hombre, maxEducLevel, oficio, estrato1) %>%
  summarise(promedio = mean(Salario_hora, na.rm = TRUE))

ggplot(promedio_ingresos, aes(x = grupo_edad, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Grupo de Edad", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = estrato1, y = promedio)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Estrato", y = "Promedio de Ingresos") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = maxEducLevel, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Nivel de Educación", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = oficio, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Oficio", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


## Dispersión Horas Trabajadas
ggplot(data = base_seleccionada , 
       mapping = aes(x = hoursWorkUsual , y = Salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Oficio
ggplot(data = base_seleccionada , 
       mapping = aes(x = oficio , y = Salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Estrato
ggplot(data = base_seleccionada , 
       mapping = aes(x = estrato1 , y = Salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

box_plot <- ggplot(data=promedio_ingresos , mapping = aes(as.factor(estrato1) , promedio)) + 
  geom_boxplot() 
box_plot

````
Punto 2D: Estadísticas Descriptivcas y Gráficos

El conjunto de datos contiene 9,423 observaciones y 29 columnas, siendo mayoritariamente numérico. La representación gráfica de los datos faltantes muestra que la mayoría de las variables están casi completas; sin embargo, algunas, como p6750, están completamente ausentes y por ello se han excluido, mientras que otras, como ingtotes, presentan una ausencia moderada (alrededor del 5%). Estos patrones guiaron las decisiones sobre la eliminación o imputación de las variables con alta incompletitud.

En cuanto a las estadísticas descriptivas de las variables principales, la variable "edad" oscila entre 19 y 86 años, con una media de aproximadamente 36.3, lo que sugiere que se trata de una muestra de población en edad laboral, inclinándose hacia etapas tempranas o medias de la carrera profesional. La variable "hombre", que representa el género, está equilibrada en alrededor del 50.4% de hombres, lo cual facilita comparaciones salariales basadas en el género. El nivel máximo de educación ("maxEducLevel") tiene una media de alrededor de 6.1 en una escala que llega hasta 7, indicando que la mayoría de los encuestados han completado la educación secundaria o niveles superiores. Aproximadamente el 21.4% de la muestra trabaja en el sector informal, mientras que el 78.6% lo hace de manera formal, lo que evidencia una presencia notable del sector informal. Por otro lado, "Salario_hora" presenta una media de aproximadamente 7,291 COP, pero con una desviación estándar elevada (alrededor de 7,643 COP), lo que señala una considerable desigualdad en los ingresos. Los "hoursWorkUsual" se sitúan típicamente en torno a las 48 horas semanales, lo que concuerda con un horario de trabajo a tiempo completo, y la variable "estrato1" varía de 1 a 6, con una media de aproximadamente 2.49, revelando que los estratos superiores están correlacionados con ingresos más altos.

Los análisis gráficos aportan información adicional sobre las relaciones entre variables. Un gráfico de barras agrupadas que muestra el Promedio de Ingresos según el Grupo de Edad y el género indica que los ingresos generalmente aumentan desde el grupo más joven (menor de 20 años) hasta los grupos de 40 a 50 años, para luego disminuir ligeramente después de los 50. Además, los hombres ganan de forma consistente más que las mujeres en cada grupo de edad, lo que resalta la brecha salarial de género, especialmente en la etapa media de la carrera. Otro gráfico de barras que relaciona el Promedio de Ingresos con el Estrato muestra una clara relación positiva, donde los estratos más bajos (1-2) presentan ingresos considerablemente inferiores y los estratos más altos (4-6) alcanzan, en promedio, ingresos que pueden superar los 40,000 a 60,000 COP, subrayando así las desigualdades socioeconómicas que pueden estar vinculadas a la educación, el acceso a empleos y la ubicación geográfica.

Asimismo, un gráfico de barras agrupadas que relaciona el Promedio de Ingresos con el Nivel de Educación y el género revela que los ingresos aumentan notablemente a medida que se alcanza un mayor nivel educativo, lo que indica retornos significativos de la inversión en educación o capacitación especializada. La brecha salarial de género se mantiene en todos los niveles educativos, pero se ensancha en los niveles más altos (6-7), lo que sugiere que incluso los grados avanzados no eliminan completamente las disparidades salariales entre hombres y mujeres. En otro análisis, un gráfico que visualiza el Promedio de Ingresos según el Oficio (código de ocupación) y el género muestra que los ingresos varían drásticamente entre ocupaciones, con algunos roles alcanzando ingresos cercanos a 60,000 COP, mientras que otros se agrupan en niveles mucho más bajos. En este contexto, los hombres tienden a superar a las mujeres dentro de los mismos códigos ocupacionales, aunque en algunas ocupaciones la diferencia es mínima o incluso invertida, y se observan valores atípicos extremos que podrían reflejar roles especializados o posiciones gerenciales.

Otros gráficos de dispersión analizan la relación entre las horas trabajadas y el salario por hora, diferenciando por formalidad. Estos muestran que la mayoría de las personas trabajan entre 40 y 50 horas semanales, pero los salarios varían ampliamente en cualquier rango de horas, sin que exista una correlación lineal clara entre ambos. Los trabajadores formales, representados en color azul, se agrupan en rangos salariales más altos, mientras que los informales, en rojo, se concentran en niveles más bajos, lo que indica que el tipo de empleo, la habilidad y el sector son factores más determinantes para el salario que la cantidad de horas trabajadas. Otro gráfico de dispersión que relaciona el salario por hora con el código de ocupación, también coloreado por formalidad, destaca una fuerte división entre formal e informal, con los trabajadores formales acumulando salarios más elevados, y grandes variaciones dentro de la misma ocupación, lo que sugiere que otros factores como la experiencia o el estatus gerencial también inciden en la remuneración.

En resumen, estas estadísticas descriptivas y visualizaciones pintan un panorama de un mercado laboral estratificado, moldeado por el género, el estatus formal o informal, el nivel educativo y el trasfondo socioeconómico. Esta perspectiva multidimensional es esencial para futuros análisis o formulación de políticas orientadas a reducir la brecha salarial y mejorar la equidad en el empleo.

PUNTO 3: \# Age Wage Profile

```{r modelo1, include=FALSE}
# 1. Create age_squared
base_seleccionada$edad_squared <- base_seleccionada$edad^2

# 2. Regression Analysis
model <- lm(ln_Salario_hora ~ edad + edad_squared, data = base_seleccionada)

# 3. Regression Table and Interpretation
summary(model)

```
Realizamos una regresión lineal para analizar la relación entre la edad y el salario por hora, utilizando el logaritmo del salario para interpretar los coeficientes como porcentajes. Los resultados indican que la edad tiene un efecto estadísticamente significativo en el salario. Por cada año adicional, el salario tiende a aumentar, lo que se refleja en el coeficiente positivo de la variable "edad". Sin embargo, al incluir la edad al cuadrado, observamos que este efecto positivo disminuye a medida que la edad avanza, sugiriendo una posible estabilización o incluso disminución del salario en edades más avanzadas.

A pesar de la significancia estadística de la edad y la edad al cuadrado, el modelo en su conjunto no explica una gran proporción de la variación en el salario por hora. El R-cuadrado, que mide la bondad de ajuste del modelo, es bastante bajo, alrededor del 3.5%. Esto significa que nuestro modelo solo captura una pequeña parte de las diferencias salariales observadas, lo que sugiere que hay otros factores importantes que influyen en el salario y que no estamos considerando.

En conclusión, aunque la edad es un factor relevante en la determinación del salario, nuestro modelo indica que no es el único ni el más importante. El bajo ajuste del modelo sugiere que factores como la educación, la experiencia laboral o el sector de empleo podrían tener un impacto significativo en el salario por hora. Por lo tanto, aunque la edad proporciona información valiosa, se necesita un análisis más completo para entender completamente la dinámica salarial.

```{r dividir_datos, include=FALSE}
age_range <- seq(min(base_seleccionada$edad), max(base_seleccionada$edad), length.out = 100)
age_squared_range <- age_range^2
predicted_ln_wage <- predict(model, newdata = data.frame(edad = age_range, edad_squared = age_squared_range))
predicted_wage <- exp(predicted_ln_wage) # Convert log(wage) back to wage

plot(age_range, predicted_wage, type = "l", xlab = "Age (edad)", ylab = "Predicted Hourly Wage", main = "Estimated Age-Earnings Profile")
grid()

# 6. Peak Age and Confidence Intervals (Bootstrap)
peak_age <- -coef(model)["edad"] / (2 * coef(model)["edad_squared"])
print(paste("Peak Age:", round(peak_age, 2)))

n_bootstraps <- 1000
boot_peak_ages <- replicate(n_bootstraps, {
  boot_data <- base_seleccionada[sample(nrow(base_seleccionada), replace = TRUE), ]
  boot_model <- lm(ln_Salario_hora ~ edad + edad_squared, data = boot_data)
  -coef(boot_model)["edad"] / (2 * coef(boot_model)["edad_squared"])
})

lower_ci <- quantile(boot_peak_ages, 0.025)
upper_ci <- quantile(boot_peak_ages, 0.975)
print(paste("95% Confidence Interval for Peak Age:", paste("(", round(lower_ci, 2), ",", round(upper_ci, 2), ")")))
```
El gráfico muestra cómo el salario por hora predicho cambia con la edad. Inicialmente, el salario aumenta rápidamente, alcanzando un pico alrededor de los 45-47 años, y luego disminuye gradualmente. Los resultados numéricos confirman que la edad pico estimada es de aproximadamente 45.69 años, con un intervalo de confianza del 95% entre 44.38 y 47.29 años. Esto sugiere que, en promedio, los trabajadores alcanzan su salario máximo a mediados de sus 40, seguido de una disminución en las etapas posteriores de la vida laboral.

#Punto 5: 

# Dividir Datos en Entrenamiento y Prueba

```{r dividir_datos, include=FALSE}
set.seed(10101)
datos_filtrados$id <- 1:nrow(datos_filtrados)
datos_entrenamiento <- datos_filtrados %>% sample_frac(0.7)
datos_prueba <- datos_filtrados %>% anti_join(datos_entrenamiento, by = "id")

cat("Tamaño del conjunto de entrenamiento:", nrow(datos_entrenamiento), "\n")
cat("Tamaño del conjunto de prueba:", nrow(datos_prueba), "\n")
```

# Modelos de Regresión

## Modelo 1: Constante

```{r modelo1, include=FALSE}
modelo1 <- lm(ln_Salario_hora ~ 1, data = datos_entrenamiento)
summary(modelo1)
```

## Modelo 2: Edad y Edad\^2

```{r modelo2, include=FALSE}
modelo2 <- lm(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento)
summary(modelo2)
```

## Modelo 3: Género y Edad

```{r modelo3, include=FALSE}
modelo3 <- lm(ln_Salario_hora ~ hombre + edad, data = datos_entrenamiento)
summary(modelo3)
```

# Evaluación de Modelos (RMSE)

```{r evaluacion, include=FALSE}
rmse <- function(actual, predicho) {
sqrt(mean((actual - predicho)^2))
}

datos_prueba$prediccion_m1 <- predict(modelo1, newdata = datos_prueba)
datos_prueba$prediccion_m2 <- predict(modelo2, newdata = datos_prueba)
datos_prueba$prediccion_m3 <- predict(modelo3, newdata = datos_prueba)

rmse_m1 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m1)
rmse_m2 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m2)
rmse_m3 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m3)

cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
```

# Intervalos de Confianza mediante Bootstrap

```{r bootstrap, include=FALSE}
# Función para bootstrap del coeficiente de edad
boot_fn <- function(data, indices) {
modelo_boot <- lm(ln_Salario_hora ~ edad + I(edad^2), data = data[indices, ])
return(coef(modelo_boot))
}

boot_results <- boot(datos_entrenamiento, boot_fn, R = 1000)

# Intervalo de confianza al 95% para el coeficiente de edad
boot.ci(boot_results, type = "perc", index = 2)
```

# Visualización de la Curva de Edad-Ingreso

```{r curva_edad_ingreso, include=FALSE}
edad_seq <- data.frame(edad = seq(min(datos_entrenamiento$edad), max(datos_entrenamiento$edad), by = 1))
edad_seq$ln_Salario_hora_pred <- predict(modelo2, newdata = edad_seq)

curv_edad_salario <- ggplot(datos_entrenamiento, aes(x = edad, y = ln_Salario_hora)) +
geom_point(alpha = 0.3) +
geom_line(data = edad_seq, aes(x = edad, y = ln_Salario_hora_pred), color = "blue") +
labs(title = "Curva de Edad vs. Log Salario Hora",
x = "Edad", y = "Log Salario Hora")

print(curv_edad_salario)
```

# Comparación entre Modelos Condicionales y No Condicionales

```{r comparacion_modelos, include=FALSE}
modelo_sin_controles <- lm(ln_Salario_hora ~ hombre, data = datos_entrenamiento)
modelo_con_controles <- lm(ln_Salario_hora ~ hombre + edad + T_horas_trabajadas, data = datos_entrenamiento)

stargazer(modelo_sin_controles, modelo_con_controles, type = "text", title = "Comparación de Modelos")
```

# Validación Cruzada (5-fold)

```{r validacion_cruzada, include=FALSE}
train_control <- trainControl(method = "cv", number = 5)
modelo_cv <- train(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento, method = "lm", trControl = train_control)
print(modelo_cv)
```

# Modelos Adicionales (Polinomiales e Interacciones)

```{r modelos_adicionales, include=FALSE}
modelo4 <- lm(ln_Salario_hora ~ poly(edad, 3, raw = TRUE), data = datos_entrenamiento)
modelo5 <- lm(ln_Salario_hora ~ hombre * edad, data = datos_entrenamiento)
modelo6 <- lm(ln_Salario_hora ~ hombre + edad + I(edad^2) + T_horas_trabajadas, data = datos_entrenamiento)
modelo7 <- lm(ln_Salario_hora ~ poly(edad, 2) + log(T_horas_trabajadas), data = datos_entrenamiento)

# Predicciones y RMSE para los nuevos modelos
datos_prueba$prediccion_m4 <- predict(modelo4, newdata = datos_prueba)
datos_prueba$prediccion_m5 <- predict(modelo5, newdata = datos_prueba)
datos_prueba$prediccion_m6 <- predict(modelo6, newdata = datos_prueba)
datos_prueba$prediccion_m7 <- predict(modelo7, newdata = datos_prueba)

rmse_m4 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m4)
rmse_m5 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m5)
rmse_m6 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m6)
rmse_m7 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m7)
```

# Mostrar los resultados de RMSE para todos los modelos

```{r resultados_rmse, include=FALSE}
cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
cat("RMSE Modelo 4:", round(rmse_m4, 4), "\n")
cat("RMSE Modelo 5:", round(rmse_m5, 4), "\n")
cat("RMSE Modelo 6:", round(rmse_m6, 4), "\n")
cat("RMSE Modelo 7:", round(rmse_m7, 4), "\n")
```

# Comparación gráfica de los errores de predicción entre los modelos

```{r comparacion_grafica, include=FALSE}
mse_values <- data.frame(
Modelo = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5", "Modelo 6", "Modelo 7"),
RMSE = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6, rmse_m7)
)

# Visualizar los RMSE en un gráfico de barras

RMSE_barras <- ggplot(mse_values, aes(x = Modelo, y = RMSE, fill = Modelo)) +
geom_bar(stat = "identity", show.legend = FALSE) +
labs(title = "Comparación de RMSE entre Modelos",
x = "Modelo", y = "RMSE") +
theme_minimal()

print(RMSE_barras)
```

Rendimiento General de los Modelos:

El análisis comparativo de los modelos de regresión revela que, en general, el rendimiento predictivo es modesto, como lo indican los bajos valores de R-cuadrado y los RMSE relativamente altos. Esto sugiere que la variabilidad en el logaritmo del salario por hora no se explica completamente por las variables incluidas en los modelos. A pesar de esto, se observa una mejora en el ajuste cuando se incorporan la edad y su término cuadrático, lo que destaca la importancia de considerar la no linealidad en la relación entre la edad y el salario. El modelo 6, en particular, presenta el menor error de predicción (RMSE de 0.6173), indicando un mejor rendimiento en comparación con las otras especificaciones. Además, el modelo que incluye las horas trabajadas, el género y la edad muestra el mejor ajuste a los datos de entrenamiento, lo que sugiere que estas variables son relevantes para predecir el salario por hora.

Especificación con el Menor Error de Predicción:

El modelo 6 se destaca por tener el menor error de predicción (RMSE de 0.6173) entre todas las especificaciones evaluadas. Sin embargo, para proporcionar un análisis más detallado de este modelo, sería necesario conocer las variables específicas que lo componen. El modelo que mejor se ajusta a los datos de entrenamiento es aquel que incluye las horas trabajadas, el género y la edad, lo que sugiere que estas variables son determinantes importantes del salario por hora.

Exploración de Observaciones con Errores de Predicción Significativos:

Para el modelo con el menor error de predicción (Modelo 6), se propone calcular los errores de predicción en el conjunto de prueba y examinar su distribución. Identificar las observaciones con errores grandes, tanto positivos como negativos, permitirá analizar sus características y determinar si representan outliers genuinos o errores del modelo. Los outliers podrían ser de interés para la DIAN si representan individuos con ingresos atípicos y bajos impuestos declarados, aunque también podrían ser producto de las limitaciones del modelo. Se recomienda realizar un análisis más profundo de las variables del Modelo 6 y considerar la inclusión de variables adicionales para mejorar la precisión predictiva.
