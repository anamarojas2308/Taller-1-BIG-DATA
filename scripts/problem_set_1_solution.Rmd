---
title: "Taller_1"
author: "group_5"
date: "2025-03-02"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Configuración Inicial, limpiar entorno y ambiente de trabajo
rm(list = ls())
gc()
closeAllConnections()
```

```{r}
# Cargar librerías necesarias
load.lib <- c('data.table', 'dplyr', 'ggplot2', 'stargazer', 'tidyverse', 'lubridate',
'plotly', 'rvest', 'tm', 'wordcloud', 'caret', 'boot', 'pacman','skimr')

install.lib <- load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib)
sapply(load.lib, require, character = TRUE)

print("Librerías cargadas correctamente")

```

# Problem Set 1: Predicting Income

## Introduction

In the public sector, accurate reporting of individual income is
critical for computing taxes. However, tax fraud of all kinds has always
been a significant issue. According to the Internal Revenue Service
(IRS), about 83.6% of taxes are paid voluntarily and on time in the
US.1. One of the causes of this gap is the under-reporting of incomes by
individuals. An income predicting model could potentially assist in
flagging cases of fraud that could lead to the reduction of the gap.
Furthermore, an income prediction model can help identify vulnerable
individuals and families that may need further assistance.

The objective of the problem set is to apply the concepts we learned
using “real” world data. For that, we are going to scrape from the
following website:
  <https://ignaciomsarmiento.github.io/GEIH2018-sample/> This website
contains data for Bogotá from the 2018 “Medición de Pobreza Monetaria
y Desigualdad Report” that takes information from the
[GEIH.](https://www.dane.gov.co/index.php/estadisticas-por-tema/mercado-laboral/empleo-y-desempleo/geih-historicos)


### General Instructions

The main objective is to construct a model of individual hourly wages

$$w = f(X)+u$$
  
  where $w$ is the hourly wage, and $X$ is a matrix that includes
potential explanatory variables/predictors. In this problem set, we will
focus on $f(X) = X\beta$. The final document, in .pdf format, must
contain the following sections:

1.*Introduction.* The introduction briefly states the problem and if there are any antecedents. It briefly describes the data and its suitability to address the problem set question. It contains a preview of the results and main takeaways.

2.*Data.* We will use data for Bogot´a from the 2018 “Medición de Pobreza Monetaria y Desigualdad Report” that takes information from the GEIH.

The data set contains all individuals sampled in Bogota and is available at the following website <https://ignaciomsarmiento.github.io/GEIH2018-sample/>. To obtain
the data, you must scrape the website.

In this problem set, we will focus only on employed individuals older than eighteen (18) years old. Restrict the data to these individuals and perform a descriptive analysis of the variables used in the problem set. Keep in mind that in the data, there are many observations with missing data or 0 wages. I leave it to you to find a way to handle this data

When writing this section up, you must:

(a) Describe the data briefly, including its purpose, and any other relevant information.

(b) Describe the process of acquiring the data and if there are any restrictions to accessing/scraping these data.
(c) Describe the data cleaning process and
(d) Descriptive the variables included in your analysis. At a minimum, you should include a descriptive statistics table with its interpretation. However, I expect a deep analysis that helps the reader understand the data, its variation, and the justification for your data choices. Use your professional knowledge to add value to this section. Do not present it as a “dry” list of ingredients.
```{r}
# Web Scraping de el dataset-GEIH 2018 proporcionados por el profesor Ignacio Sarmiento
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
pagina <- read_html(paste0(url_base, "1.html"))
datos_totales <- pagina %>% html_table(fill = TRUE) %>% .[[1]]

for (i in 2:10) {
  url <- paste0(url_base, i, ".html")
  tryCatch({
    pagina <- read_html(url)
    tabla <- pagina %>% html_table(fill = TRUE) %>% .[[1]]
    datos_totales <- bind_rows(datos_totales, tabla)
  }, error = function(e) {
    message(paste("Error al cargar la página", i, ":", e))
  })
}

head(datos_totales)

#Guardar el dataset "scrapeado"
datos_totales <- write.csv(datos_totales, "datos_totales.csv")

# Importar el dataset-GEIH 2018
datos_totales <- read_csv("datos_totales.csv")

```

```{r}
# Renombrar columnas y limpiar Datos
datos_totales <- datos_totales %>%
  rename(ingreso_total = ingtot,
         edad = age,
         hombre = sex,
         escolaridad = maxEducLevel,
         cuentapropia = cuentaPropia,
         t_horas_trabajadas = totalHoursWorked,
         salario_hora = y_salary_m_hu) %>%
  mutate(ln_salario_hora = log(salario_hora))

# Filtrar registros inválidos 
datos_filtrados <- datos_totales %>%
  filter(edad > 18, ingreso_total > 0, t_horas_trabajadas > 0, 
        salario_hora > 0)

# Identificar y eliminar outliers usando percentiles 1% y 99%
low_hours <- quantile(datos_filtrados$t_horas_trabajadas, 0.01)
up_hours <- quantile(datos_filtrados$t_horas_trabajadas, 0.99)
low_salary <- quantile(datos_filtrados$salario_hora, 0.01)
up_salary <- quantile(datos_filtrados$salario_hora, 0.99)

datos_filtrados <- datos_filtrados %>%
  filter(t_horas_trabajadas >= low_hours & t_horas_trabajadas <= up_hours,
         salario_hora >= low_salary & salario_hora <= up_salary)

# Codificación de variables de interés
datos_filtrados <- datos_filtrados %>% 
  mutate(jefe = case_when(p6050 == "1" ~ 1,
                          TRUE ~ 0),
         mujer = case_when(hombre == "1" ~ 0,
                           TRUE ~ 1))


# Seleccionar unicamente la variable de Salario Hora, no ingresos
numericas <- datos_filtrados %>% select(-all_of(c("y_ingLab_m_ha", "y_total_m_ha", "p6500", "y_salary_m", 
                                                  "impa", "y_ingLab_m", "y_total_m", "ingtotob", "ingreso_total")))

# Seleccionar las columnas numéricas del dataframe
numericas <- numericas[, sapply(numericas, is.numeric)]

# Filtrar las columnas con desviación estándar diferente a cero y sin valores NA
numericas_filtradas <- numericas[, sapply(numericas, function(x) {
  !all(is.na(x)) && sd(x, na.rm = TRUE) != 0
})]

# Ver el resumen de las columnas filtradas
summary(numericas_filtradas)

# Calcular la correlación de cada variable con 'ingreso_total'
correlaciones_con_y <- sapply(numericas_filtradas, function(x) cor(x, numericas$salario_hora, use = "complete.obs"))

# Crear el dataframe con las correlaciones
resultados_correlacion <- data.frame(Variable = names(correlaciones_con_y), Correlacion_con_y = correlaciones_con_y)

# Mostrar los resultados
print(resultados_correlacion)

# Compute the absolute value of the correlations with 'Salario_hora'
correlaciones_abs <- abs(correlaciones_con_y)

# Sort the correlations in descending order
correlaciones_abs_sorted <- sort(correlaciones_abs, decreasing = TRUE)
print(correlaciones_abs_sorted)

# Select the names of the top 25 variables with the highest correlation
top_25_vars <- names(correlaciones_abs_sorted)[1:25]

# Create a new dataframe with the top 25 variables and their corresponding correlations
top_25_correlaciones <- data.frame(Variable = top_25_vars,
                                   Correlacion_con_y = correlaciones_abs_sorted[1:25])

# Print the results
print(top_25_correlaciones)




# Seleccionar variables importantes para el modelo 

variables_seleccionadas <- c("edad", "clase", "hombre","mujer","college", "depto", "escolaridad", "ocu", "dsi", "informal", "formal", "cuentapropia", "microEmpresa", "salario_hora", "ingtotes", "impa", "isa", "p6500", "p6510", "p6580", "p6750", "p7070", "cotPension", "p6920", "hoursWorkUsual", "hoursWorkActualSecondJob", "fex_c", "fweight", "oficio", "estrato1", "ln_salario_hora", "jefe")

base_seleccionada <- datos_filtrados %>% select(all_of(variables_seleccionadas))

skim(base_seleccionada) 

miss_values <- skim(base_seleccionada) %>% select( skim_variable, n_missing)
Nobs <- nrow(base_seleccionada) 
# percentage of missing
miss_values <- miss_values %>% mutate(p_missing= n_missing/Nobs)
miss_values <- miss_values %>% arrange(-n_missing)

ggplot(miss_values, aes(x = reorder(skim_variable, +p_missing) , y =  p_missing)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(title = "N Missing Per Variable", x = "Var Name", y = "Missings")+ 
  theme(axis.text = element_text(size = 5)) 

# Borrar aquellas variables con más del 90% de missing values ya que imputarlas puede traer más ruido que otra cosa
var_miss <- miss_values %>% filter (p_missing > 0.9)
base_seleccionada <- base_seleccionada %>% select(-all_of(var_miss[[1]]))

# Loop through each column and display descriptive statistics
for (col_name in colnames(base_seleccionada)) {
  cat("Descriptive statistics for", col_name, ":\n")
  print(summary(base_seleccionada[[col_name]]))
  skim(base_seleccionada[[col_name]])
  cat("\n")
}

#Usar cut para crear los grupos de edad
base_seleccionada$grupo_edad <- cut(base_seleccionada$edad, 
                                    breaks = c(-Inf, 20, 30, 40, 50, 60, 70, Inf), 
                                    labels = c("<20", "20-30", "30-40", "40-50", "50-60", 
                                               "60-70", ">70"),
                                    right = FALSE)

base_seleccionada$hombre <- as.factor(base_seleccionada$hombre)



```

```{r}
#Calcular el promedio de ingresos por grupo de edad y género
promedio_ingresos <- base_seleccionada %>%
  group_by(grupo_edad, hombre, escolaridad, oficio, estrato1) %>%
  summarise(promedio = mean(salario_hora, na.rm = TRUE))

ggplot(promedio_ingresos, aes(x = grupo_edad, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Grupo de Edad", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = estrato1, y = promedio)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Estrato", y = "Promedio de Ingresos") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = escolaridad, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Nivel de Educación", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = oficio, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Oficio", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


## Dispersión Horas Trabajadas
ggplot(data = base_seleccionada , 
       mapping = aes(x = hoursWorkUsual , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Oficio
ggplot(data = base_seleccionada , 
       mapping = aes(x = oficio , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Estrato
ggplot(data = base_seleccionada , 
       mapping = aes(x = estrato1 , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

box_plot <- ggplot(data=promedio_ingresos , mapping = aes(as.factor(estrato1) , promedio)) + 
  geom_boxplot() 
box_plot

```

3.*Age-wage profile.*  A great deal of evidence in *labor economics* suggests that the typical worker’s age-wage profile has a predictable path: *“Wages tend to be low when the worker is young; they rise as the worker ages, peaking at about age 50; and the wage rate tends to remain stable or decline slightly after age 50”.*
  
  In this subsection we are going to estimate the Age-wage profile profile for the individuals in this sample:
  
  
  $$log(w) = \beta_{1} + \beta_{2}Age + \beta_{3} Age^{2} + u$$
  When presenting and discussing your results, include:
  
- A regression table.
- An interpretation of the coefficients and it’s significance.
- A discussion of the model’s in sample fit.
- A plot of the estimated age-earnings profile implied by the above equation. Including a discussion of the “peak age” with it’s respective confidence intervals. (Note: Use bootstrap to construct the confidence intervals.)

```{r}

#1. Create age_squared
base_seleccionada$edad_squared <- base_seleccionada$edad^2

#2. Regression Analysis
model <- lm(ln_salario_hora ~ edad + edad_squared, data = base_seleccionada)

#3. Regression Table and Interpretation
summary(model)


age_range <- seq(min(base_seleccionada$edad), max(base_seleccionada$edad), length.out = 100)
age_squared_range <- age_range^2
predicted_ln_wage <- predict(model, newdata = data.frame(edad = age_range, edad_squared = age_squared_range))
predicted_wage <- exp(predicted_ln_wage) # Convert log(wage) back to wage

plot(age_range, predicted_wage, type = "l", xlab = "Age (edad)", ylab = "Predicted Hourly Wage", main = "Estimated Age-Earnings Profile")
grid()

#6. Peak Age and Confidence Intervals (Bootstrap)
peak_age <- -coef(model)["edad"] / (2 * coef(model)["edad_squared"])
print(paste("Peak Age:", round(peak_age, 2)))

n_bootstraps <- 1000
boot_peak_ages <- replicate(n_bootstraps, {
  boot_data <- base_seleccionada[sample(nrow(base_seleccionada), replace = TRUE), ]
  boot_model <- lm(ln_salario_hora ~ edad + edad_squared, data = boot_data)
  -coef(boot_model)["edad"] / (2 * coef(boot_model)["edad_squared"])
})

lower_ci <- quantile(boot_peak_ages, 0.025)
upper_ci <- quantile(boot_peak_ages, 0.975)
print(paste("95% Confidence Interval for Peak Age:", paste("(", round(lower_ci, 2), ",", round(upper_ci, 2), ")")))

```


# Punto 4

4. *The gender earnings GAP.* Policymakers have long been concerned with the gender wage gap, and is going to be our focus in this subsection.

(a) Begin by estimating and discussing the unconditional wage gap:
  
  $$log(w) = \beta_{1} + \beta_{2}Female + u$$
  where *Female* is an indicator that takes one if the individual in the sample is
identified as female.

(b) *Equal Pay for Equal Work?* A common slogan is“equal pay for equal work”. One way to interpret this is that for employees with similar worker and job characteristics, no gender wage gap should exist. Estimate a conditional earnings gap incorporating control variables such as similar worker and job characteristics.
In this section, estimate the conditional wage gap:
  
  - First, using FWL
  - Second, using FWL with bootstrap. Compare the estimates and the standard errors.

(c) Next, plot the predicted age-wage profile and estimate the implied “peak ages” with the respective confidence intervals by gender

When presenting and discussing your results, include:
  
  - An estimating equation, explaining the included control variables *(beware of “bad controls”).*
  - A regression table, with the estimates side by side of the conditional and unconditional wage gaps, highlighting the coefficient of interest. Controls, should
not be included in the table but dutifully noted.
- An interpretation of the“Female” coefficients, a comparison between the models, and the in-sample fit.
- A discussion about the implied peak ages and their statistical similarity/difference.
- A thoughtful discussion about the unconditional and conditional wage gap, seeking to answer if the changes in the coefficient are evidence of a selection problem, a ”discrimination problem,” a mix, or none of these issues.




```{r}
# Modelo incondicional
modelo_incondicional <- lm(ln_salario_hora ~ mujer, data = base_seleccionada)
summary(modelo_incondicional)
stargazer(modelo_incondicional, type = "text")
```

```{r}
# Variables de control, modelo condicional
controles <- lm(ln_salario_hora ~ mujer + escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = base_seleccionada)
summary(controles)
stargazer(controles, type = "text")
residuos_salario <- residuals(controles)

controles_genero <- lm(mujer ~ escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = base_seleccionada)
residuos_genero <- residuals(controles_genero)

# Modelo FWL
modelo_fwl <- lm(residuos_salario ~ residuos_genero)
summary(modelo_fwl)
```

```{r}
# Bootstrap para FWL
fwl_bootstrap <- function(data, indices) {
  datos_boot <- data[indices, ]
  controles <- lm(ln_salario_hora ~ mujer + escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = datos_boot)
  residuos_salario <- residuals(controles)
  
  controles_genero <- lm(mujer ~ escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = datos_boot)
  residuos_genero <- residuals(controles_genero)
  
  modelo <- lm(residuos_salario ~ residuos_genero)
  coef(modelo)[2] # Devuelve el coeficiente para "residuos_genero"
}

# Aplicar bootstrap
resultados_bootstrap <- boot(data = base_seleccionada, statistic = fwl_bootstrap, R = 1000)
summary(resultados_bootstrap)
```


```{r}
stargazer(modelo_incondicional, controles, type = "text", omit = c("escolaridad", "edad", "cuentapropia", "jefe", "formal", "I(edad2)", "ocu"))

```


```{r}
# Modelo polinómico para edad
modelo_edad <- lm(ln_salario_hora ~ edad + I(edad^2) + mujer, data = base_seleccionada)
summary(modelo_edad)

# Edad "punta"
edad_punta <- -coef(modelo_edad)["Edad"] / (2 * coef(modelo_edad)["I(Edad^2)"])
intervalo_confianza <- confint(modelo_edad)

# Gráfico edad-salario
ggplot(base_seleccionada, aes(x = edad, y = ln_salario_hora, color = mujer)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE) +
  labs(title = "Perfil Edad-Salario", x = "Edad", y = "Salario")
```

5.*Predicting earnings.* In the previous sections, you estimated some specifications with
inference in mind. In this subsection, we will evaluate the predictive power of these
specifications.

(a) Split the sample into two: a training (70%) and a testing (30%) sample. (Don’t forget to set a seed to achieve reproducibility. In R, for example you can use set.seed(10101), where 10101 is the seed.)

(b) Report and compare the predictive performance in terms of the RMSE of all
the previous specifications with at least five (5) additional specifications that
explore non-linearities and complexity.

(c) In your discussion of the results, comment:
  
  - About the overall performance of the models.
  - About the specification with the lowest prediction error.
  - For the specification with the lowest prediction error, explore those observations that seem to ”miss the mark.” To do so, compute the prediction errors in the test sample, and examine its distribution. Are there any observations in the tails of the prediction error distribution? Are these outliers potential people that the DIAN should look into, or are they just the product of a flawed model?
  
(d) LOOCV. For the two models with the lowest predictive error in the previous section, calculate the predictive error using Leave-one-out-cross-validation
(LOOCV). Compare the results of the test error with those obtained with the
validation set approach and explore the potential links with the influence statistic. (Note: when attempting this subsection, the calculati

```{r}
set.seed(10101)
datos_filtrados$id <- 1:nrow(datos_filtrados)
datos_entrenamiento <- datos_filtrados %>% sample_frac(0.7)
datos_prueba <- datos_filtrados %>% anti_join(datos_entrenamiento, by = "id")

cat("Tamaño del conjunto de entrenamiento:", nrow(datos_entrenamiento), "\n")
cat("Tamaño del conjunto de prueba:", nrow(datos_prueba), "\n")



# Modelos de Regresión

## Modelo 1: Constante

modelo1 <- lm(ln_salario_hora ~ 1, data = datos_entrenamiento)
summary(modelo1)

## Modelo 2: Edad y Edad\^2

modelo2 <- lm(ln_salario_hora ~ edad + I(edad^2), data = datos_entrenamiento)
summary(modelo2)

## Modelo 3: Género y Edad

modelo3 <- lm(ln_salario_hora ~ hombre + edad, data = datos_entrenamiento)
summary(modelo3)

# Evaluación de Modelos (RMSE)
rmse <- function(actual, predicho) {
  sqrt(mean((actual - predicho)^2))
}

datos_prueba$prediccion_m1 <- predict(modelo1, newdata = datos_prueba)
datos_prueba$prediccion_m2 <- predict(modelo2, newdata = datos_prueba)
datos_prueba$prediccion_m3 <- predict(modelo3, newdata = datos_prueba)

rmse_m1 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m1)
rmse_m2 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m2)
rmse_m3 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m3)

cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")


# Intervalos de Confianza mediante Bootstrap
# Función para bootstrap del coeficiente de edad
boot_fn <- function(data, indices) {
  modelo_boot <- lm(ln_salario_hora ~ edad + I(edad^2), data = data[indices, ])
  return(coef(modelo_boot))
}

boot_results <- boot(datos_entrenamiento, boot_fn, R = 1000)

# Intervalo de confianza al 95% para el coeficiente de edad
boot.ci(boot_results, type = "perc", index = 2)

# Visualización de la Curva de Edad-Ingreso
edad_seq <- data.frame(edad = seq(min(datos_entrenamiento$edad), max(datos_entrenamiento$edad), by = 1))
edad_seq$ln_salario_hora_pred <- predict(modelo2, newdata = edad_seq)

curv_edad_salario <- ggplot(datos_entrenamiento, aes(x = edad, y = ln_salario_hora)) +
  geom_point(alpha = 0.3) +
  geom_line(data = edad_seq, aes(x = edad, y = ln_salario_hora_pred), color = "blue") +
  labs(title = "Curva de Edad vs. Log Salario Hora",
       x = "Edad", y = "Log Salario Hora")

print(curv_edad_salario)

# Comparación entre Modelos Condicionales y No Condicionales

modelo_sin_controles <- lm(ln_salario_hora ~ hombre, data = datos_entrenamiento)
modelo_con_controles <- lm(ln_salario_hora ~ hombre + edad + T_horas_trabajadas, data = datos_entrenamiento)

stargazer(modelo_sin_controles, modelo_con_controles, type = "text", title = "Comparación de Modelos")

# Validación Cruzada (5-fold)

train_control <- trainControl(method = "cv", number = 5)
modelo_cv <- train(ln_salario_hora ~ edad + I(edad^2), data = datos_entrenamiento, method = "lm", trControl = train_control)
print(modelo_cv)

# Modelos Adicionales (Polinomiales e Interacciones)
modelo4 <- lm(ln_salario_hora ~ poly(edad, 3, raw = TRUE), data = datos_entrenamiento)
modelo5 <- lm(ln_salario_hora ~ hombre * edad, data = datos_entrenamiento)
modelo6 <- lm(ln_salario_hora ~ hombre + edad + I(edad^2) + t_horas_trabajadas, data = datos_entrenamiento)
modelo7 <- lm(ln_salario_hora ~ poly(edad, 2) + log(t_horas_trabajadas), data = datos_entrenamiento)

# Predicciones y RMSE para los nuevos modelos
datos_prueba$prediccion_m4 <- predict(modelo4, newdata = datos_prueba)
datos_prueba$prediccion_m5 <- predict(modelo5, newdata = datos_prueba)
datos_prueba$prediccion_m6 <- predict(modelo6, newdata = datos_prueba)
datos_prueba$prediccion_m7 <- predict(modelo7, newdata = datos_prueba)

rmse_m4 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m4)
rmse_m5 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m5)
rmse_m6 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m6)
rmse_m7 <- rmse(datos_prueba$ln_salario_hora, datos_prueba$prediccion_m7)

# Mostrar los resultados de RMSE para todos los modelos

cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
cat("RMSE Modelo 4:", round(rmse_m4, 4), "\n")
cat("RMSE Modelo 5:", round(rmse_m5, 4), "\n")
cat("RMSE Modelo 6:", round(rmse_m6, 4), "\n")
cat("RMSE Modelo 7:", round(rmse_m7, 4), "\n")

# Comparación gráfica de los errores de predicción entre los modelos

mse_values <- data.frame(
  Modelo = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5", "Modelo 6", "Modelo 7"),
  RMSE = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6, rmse_m7)
)

# Visualizar los RMSE en un gráfico de barras

RMSE_barras <- ggplot(mse_values, aes(x = Modelo, y = RMSE, fill = Modelo)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(title = "Comparación de RMSE entre Modelos",
       x = "Modelo", y = "RMSE") +
  theme_minimal()

print(RMSE_barras)
```
