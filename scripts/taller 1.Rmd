---
title: "Taller_1_BDML"
authors: "Julian Delgado Gutierrez, Ana María Rojas, Juan David Rincón, Mario Andrés Mercado"
date: "2025-02-19"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem Set 1: Predicting Income

## Introduction

In the public sector, accurate reporting of individual income is
critical for computing taxes. However, tax fraud of all kinds has always
been a significant issue. According to the Internal Revenue Service
(IRS), about 83.6% of taxes are paid voluntarily and on time in the
US.1. One of the causes of this gap is the under-reporting of incomes by
individuals. An income predicting model could potentially assist in
flagging cases of fraud that could lead to the reduction of the gap.
Furthermore, an income prediction model can help identify vulnerable
individuals and families that may need further assistance.

The objective of the problem set is to apply the concepts we learned
using “real” world data. For that, we are going to scrape from the
following website:
<https://ignaciomsarmiento.github.io/GEIH2018-sample/> This website
contains data for Bogotá from the 2018 “Medición de Pobreza Monetaria
y Desigualdad Report” that takes information from the
[GEIH.](https://www.dane.gov.co/index.php/estadisticas-por-tema/mercado-laboral/empleo-y-desempleo/geih-historicos)

### General Instructions

The main objective is to construct a model of individual hourly wages

$$w = f(X)+u$$

where $w$ is the hourly wage, and $X$ is a matrix that includes
potential explanatory variables/predictors. In this problem set, we will
focus on $f(X) = X\beta$. The final document, in .pdf format, must
contain the following sections:

1.  *Introduction.* The introduction briefly states the problem and if there are any antecedents. It briefly describes the data and its suitability to address the problem set question. It contains a preview of the results and main takeaways.

2. *Data.* We will use data for Bogot´a from the 2018 “Medición de Pobreza Monetaria y Desigualdad Report” that takes information from the GEIH.

The data set contains all individuals sampled in Bogota and is available at the following website <https://ignaciomsarmiento.github.io/GEIH2018-sample/>. To obtain
the data, you must scrape the website.

In this problem set, we will focus only on employed individuals older than eighteen (18) years old. Restrict the data to these individuals and perform a descriptive analysis of the variables used in the problem set. Keep in mind that in the data, there are many observations with missing data or 0 wages. I leave it to you to find a way to handle this data

When writing this section up, you must:

(a) Describe the data briefly, including its purpose, and any other relevant information.
(b) Describe the process of acquiring the data and if there are any restrictions to accessing/scraping these data.
(c) Describe the data cleaning process and
(d) Descriptive the variables included in your analysis. At a minimum, you should include a descriptive statistics table with its interpretation. However, I expect a deep analysis that helps the reader understand the data, its variation, and the justification for your data choices. Use your professional knowledge to add value to this section. Do not present it as a “dry” list of ingredients.

3. *Age-wage profile.*  A great deal of evidence in *labor economics* suggests that the typical worker’s age-wage profile has a predictable path: *“Wages tend to be low when the worker is young; they rise as the worker ages, peaking at about age 50; and the wage rate tends to remain stable or decline slightly after age 50”.*

In this subsection we are going to estimate the Age-wage profile profile for the individuals in this sample:


$$log(w) = \beta_{1} + \beta_{2}Age + \beta_{3} Age^{2} + u$$
When presenting and discussing your results, include:

- A regression table.
- An interpretation of the coefficients and it’s significance.
- A discussion of the model’s in sample fit.
- A plot of the estimated age-earnings profile implied by the above equation. Including a discussion of the “peak age” with it’s respective confidence intervals. (Note: Use bootstrap to construct the confidence intervals.)

4. *The gender earnings GAP.* Policymakers have long been concerned with the gender wage gap, and is going to be our focus in this subsection.

(a) Begin by estimating and discussing the unconditional wage gap:

$$log(w) = \beta_{1} + \beta_{2}Female + u$$
where *Female* is an indicator that takes one if the individual in the sample is
identified as female.

(b) *Equal Pay for Equal Work?* A common slogan is“equal pay for equal work”. One way to interpret this is that for employees with similar worker and job characteristics, no gender wage gap should exist. Estimate a conditional earnings gap incorporating control variables such as similar worker and job characteristics.
In this section, estimate the conditional wage gap:

- First, using FWL
- Second, using FWL with bootstrap. Compare the estimates and the standard errors.

(c) Next, plot the predicted age-wage profile and estimate the implied “peak ages” with the respective confidence intervals by gender

When presenting and discussing your results, include:

- An estimating equation, explaining the included control variables *(beware of “bad controls”).*
- A regression table, with the estimates side by side of the conditional and unconditional wage gaps, highlighting the coefficient of interest. Controls, should
not be included in the table but dutifully noted.
- An interpretation of the“Female” coefficients, a comparison between the models, and the in-sample fit.
- A discussion about the implied peak ages and their statistical similarity/difference.
- A thoughtful discussion about the unconditional and conditional wage gap, seeking to answer if the changes in the coefficient are evidence of a selection problem, a ”discrimination problem,” a mix, or none of these issues.


5. *Predicting earnings.* In the previous sections, you estimated some specifications with
inference in mind. In this subsection, we will evaluate the predictive power of these
specifications.

(a) Split the sample into two: a training (70%) and a testing (30%) sample. (Don’t forget to set a seed to achieve reproducibility. In R, for example you can use set.seed(10101), where 10101 is the seed.)

(b) Report and compare the predictive performance in terms of the RMSE of all
the previous specifications with at least five (5) additional specifications that
explore non-linearities and complexity.

(c) In your discussion of the results, comment:

- About the overall performance of the models.
- About the specification with the lowest prediction error.
- For the specification with the lowest prediction error, explore those observations that seem to ”miss the mark.” To do so, compute the prediction errors
in the test sample, and examine its distribution. Are there any observations
in the tails of the prediction error distribution? Are these outliers potential
people that the DIAN should look into, or are they just the product of a
flawed model?

(d) LOOCV. For the two models with the lowest predictive error in the previous section, calculate the predictive error using Leave-one-out-cross-validation
(LOOCV). Compare the results of the test error with those obtained with the
validation set approach and explore the potential links with the influence statistic. (Note: when attempting this subsection, the calculati
























































# Configuración Inicial

```{r setup, include=FALSE}
rm(list = ls())
gc()
closeAllConnections()

# Cargar librerías necesarias
load.lib <- c('data.table', 'dplyr', 'ggplot2', 'stargazer', 'tidyverse', 'lubridate',
              'plotly', 'rvest', 'tm', 'wordcloud', 'caret', 'boot', 'pacman')

install.lib <- load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib)
sapply(load.lib, require, character = TRUE)

print("Librerías cargadas correctamente")
```

PUNTO 2: \# Web Scraping de GEIH

```{r scraping, include=FALSE}
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
pagina <- read_html(paste0(url_base, "1.html"))
datos_totales <- pagina %>% html_table(fill = TRUE) %>% .[[1]]

for (i in 2:10) {
  url <- paste0(url_base, i, ".html")
  tryCatch({
    pagina <- read_html(url)
    tabla <- pagina %>% html_table(fill = TRUE) %>% .[[1]]
    datos_totales <- bind_rows(datos_totales, tabla)
  }, error = function(e) {
    message(paste("Error al cargar la página", i, ":", e))
  })
}

head(datos_totales)
```

#PUNTO 2A: #Describir brevemente la data: #Una vez se combinan los datos
y se obtiene la base completa, se evidencia que hay información que nos
permite analizar el mercado laboral y variables ecónomicas de diferentes
individios. Se encuentra que el objetivo principal de la base de datos
es analizar ingresos (salario) y comportamientos del mercado. Hay
variables que nos permiten analizar características individuales como la
edad, género, educación, departamento, entre otras y variables que se
relacionan con la actividad laboral como los ingresos, horas trabajadas,
tipo de empleo, sector económico, entre otras. La selección de las
variables es clave puesto que permitirá evaluar los factores que
influyen en el ingreso y analizar fenómenos como la brecha salarial de
género. De igual forma, es importante mencionar que la base tiene
valores faltantes y observaciones con ingreso igual a cero, lo que
sugiere la necesidad de un proceso de limpieza antes del análisis. La
base tiene una estructura de formato tabular, la cual facilita el
procesamiento de los datos y el análisis de los mismos mediante
descripciones estadísticas. Adicionalmente, se considera que los datos
proporcionados son fundamentales para construir un modelo predictivo de
ingresos por hora y detectar como variables sociodemográficas y
laborales inciden en la remuneración de los individuos.

#PUNTO 2B: #Proceso y dificultades accediendo a la data: #En primer
lugar hay que tener presente que los datos no se pueden descargar como
un archivo, sino que se encuentran en un página web
(<https://ignaciomsarmiento.github.io/GEIH2018_sample/>), por lo cual,
es necesario hacer web scrapping para extraerlos. Los datos estaban
distribuidos en diferentes sitios web, por lo se combinaron en un único
conjunto de datos. De esta forma, se difinió la base de la URL, donde
cada página se nombró siguiendo un patrón (geih_page_1.html",
"geih_page_2.html ..., etc). Con ayuda de la libreria rvest se leyó el
contenido HTML de cada página (data chunk 1:10), se extrajeron las
tablas y se combinaron los datos en un solo dataframe, almacenando el
resultado en la variables datos_totales. Para evitar que el código fuese
a generar error en caso de que una de las páginas no cargara
correctamente, se utilizó tryCatch (manejo de errores). De esta forma,
se buscaba que si las páginas cargaban correctamente, se extrayera las
tablas y se añadieran a la variable "datos_totales" y si se llegaba a
presentar algún problema de lectura, se captaría el error sin detener la
ejecución total. Por lo tanto, el código permite automatizar el proceso
de recolección de datos que están distribuidores en diferentes sitios
web y cuando se trabaja con grandes volúmenes de datos, aún si se
presenta algún problema. No se encuentran restricciones dado que la
página no tiene capchas ni bloqueos para la extracción de datos, pero
tuvimos presente no hacer múltiples solicitudes en un corto período de
tiempo para no sobrecargar el servidor. Por el otro lado, los datos son
públicos y fueron diseñados para fines académicos, por lo que facilito
en gran medida el scrapping.

# Renombrar Columnas y Limpiar Datos

```{r limpieza, include=FALSE}
datos_totales <- datos_totales %>%
  rename(
    ingreso_total = ingtot,
    edad = age,
    hombre = sex,
    T_horas_trabajadas = totalHoursWorked,
    Salario_hora = y_salary_m_hu
  ) %>%
  mutate(
    ln_Salario_hora = log(Salario_hora)
  )

# Filtrar registros inválidos

datos_filtrados <- datos_totales %>%
  filter(edad >= 18, ingreso_total > 0, T_horas_trabajadas > 0, Salario_hora > 0)

# Identificar y eliminar outliers usando percentiles 1% y 99%
low_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.01)
up_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.99)
low_salary <- quantile(datos_filtrados$Salario_hora, 0.01)
up_salary <- quantile(datos_filtrados$Salario_hora, 0.99)

datos_filtrados <- datos_filtrados %>%
  filter(T_horas_trabajadas >= low_hours & T_horas_trabajadas <= up_hours,
         Salario_hora >= low_salary & Salario_hora <= up_salary)

```

COMPLEMENTO JUAN:

# Dividir Datos en Entrenamiento y Prueba

```{r dividir_datos, include=FALSE}
set.seed(10101)
datos_filtrados$id <- 1:nrow(datos_filtrados)
datos_entrenamiento <- datos_filtrados %>% sample_frac(0.7)
datos_prueba <- datos_filtrados %>% anti_join(datos_entrenamiento, by = "id")

cat("Tamaño del conjunto de entrenamiento:", nrow(datos_entrenamiento), "\n")
cat("Tamaño del conjunto de prueba:", nrow(datos_prueba), "\n")
```

# Modelos de Regresión

## Modelo 1: Constante

```{r modelo1, include=FALSE}
modelo1 <- lm(ln_Salario_hora ~ 1, data = datos_entrenamiento)
summary(modelo1)
```

## Modelo 2: Edad y Edad\^2

```{r modelo2, include=FALSE}
modelo2 <- lm(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento)
summary(modelo2)
```

## Modelo 3: Género y Edad

```{r modelo3, include=FALSE}
modelo3 <- lm(ln_Salario_hora ~ hombre + edad, data = datos_entrenamiento)
summary(modelo3)
```

# Evaluación de Modelos (RMSE)

```{r evaluacion, include=FALSE}
rmse <- function(actual, predicho) {
  sqrt(mean((actual - predicho)^2))
}

datos_prueba$prediccion_m1 <- predict(modelo1, newdata = datos_prueba)
datos_prueba$prediccion_m2 <- predict(modelo2, newdata = datos_prueba)
datos_prueba$prediccion_m3 <- predict(modelo3, newdata = datos_prueba)

rmse_m1 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m1)
rmse_m2 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m2)
rmse_m3 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m3)

cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
```

# Intervalos de Confianza mediante Bootstrap

```{r bootstrap, include=FALSE}
# Función para bootstrap del coeficiente de edad
boot_fn <- function(data, indices) {
  modelo_boot <- lm(ln_Salario_hora ~ edad + I(edad^2), data = data[indices, ])
  return(coef(modelo_boot))
}

boot_results <- boot(datos_entrenamiento, boot_fn, R = 1000)

# Intervalo de confianza al 95% para el coeficiente de edad
boot.ci(boot_results, type = "perc", index = 2)
```

# Visualización de la Curva de Edad-Ingreso

```{r curva_edad_ingreso, include=FALSE}
edad_seq <- data.frame(edad = seq(min(datos_entrenamiento$edad), max(datos_entrenamiento$edad), by = 1))
edad_seq$ln_Salario_hora_pred <- predict(modelo2, newdata = edad_seq)

curv_edad_salario <- ggplot(datos_entrenamiento, aes(x = edad, y = ln_Salario_hora)) +
                      geom_point(alpha = 0.3) +
                      geom_line(data = edad_seq, aes(x = edad, y = ln_Salario_hora_pred), color = "blue") +
                      labs(title = "Curva de Edad vs. Log Salario Hora",
                       x = "Edad", y = "Log Salario Hora")

print(curv_edad_salario)
```

# Comparación entre Modelos Condicionales y No Condicionales

```{r comparacion_modelos, include=FALSE}
modelo_sin_controles <- lm(ln_Salario_hora ~ hombre, data = datos_entrenamiento)
modelo_con_controles <- lm(ln_Salario_hora ~ hombre + edad + T_horas_trabajadas, data = datos_entrenamiento)

stargazer(modelo_sin_controles, modelo_con_controles, type = "text", title = "Comparación de Modelos")
```

# Validación Cruzada (5-fold)

```{r validacion_cruzada, include=FALSE}
train_control <- trainControl(method = "cv", number = 5)
modelo_cv <- train(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento, method = "lm", trControl = train_control)
print(modelo_cv)
```

# Modelos Adicionales (Polinomiales e Interacciones)

```{r modelos_adicionales, include=FALSE}
modelo4 <- lm(ln_Salario_hora ~ poly(edad, 3, raw = TRUE), data = datos_entrenamiento)
modelo5 <- lm(ln_Salario_hora ~ hombre * edad, data = datos_entrenamiento)
modelo6 <- lm(ln_Salario_hora ~ hombre + edad + I(edad^2) + T_horas_trabajadas, data = datos_entrenamiento)
modelo7 <- lm(ln_Salario_hora ~ poly(edad, 2) + log(T_horas_trabajadas), data = datos_entrenamiento)

# Predicciones y RMSE para los nuevos modelos
datos_prueba$prediccion_m4 <- predict(modelo4, newdata = datos_prueba)
datos_prueba$prediccion_m5 <- predict(modelo5, newdata = datos_prueba)
datos_prueba$prediccion_m6 <- predict(modelo6, newdata = datos_prueba)
datos_prueba$prediccion_m7 <- predict(modelo7, newdata = datos_prueba)

rmse_m4 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m4)
rmse_m5 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m5)
rmse_m6 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m6)
rmse_m7 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m7)
```

# Mostrar los resultados de RMSE para todos los modelos

```{r resultados_rmse, include=FALSE}
cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
cat("RMSE Modelo 4:", round(rmse_m4, 4), "\n")
cat("RMSE Modelo 5:", round(rmse_m5, 4), "\n")
cat("RMSE Modelo 6:", round(rmse_m6, 4), "\n")
cat("RMSE Modelo 7:", round(rmse_m7, 4), "\n")
```

# Comparación gráfica de los errores de predicción entre los modelos

```{r comparacion_grafica, include=FALSE}
mse_values <- data.frame(
  Modelo = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5", "Modelo 6", "Modelo 7"),
  RMSE = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6, rmse_m7)
)

# Visualizar los RMSE en un gráfico de barras

RMSE_barras <- ggplot(mse_values, aes(x = Modelo, y = RMSE, fill = Modelo)) +
                 geom_bar(stat = "identity", show.legend = FALSE) +
                 labs(title = "Comparación de RMSE entre Modelos",
                      x = "Modelo", y = "RMSE") +
                 theme_minimal()

print(RMSE_barras)
```
