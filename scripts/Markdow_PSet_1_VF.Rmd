---
title: "Taller_1"
author: "group_5"
date: "2025-03-02"
output: pdf_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Configuración Inicial, limpiar entorno y ambiente de trabajo
rm(list = ls())
gc()
closeAllConnections()
```

```{r}
# Cargar librerías necesarias
load.lib <- c('data.table', 'dplyr', 'ggplot2', 'stargazer', 'tidyverse', 'lubridate',
'plotly', 'rvest', 'tm', 'wordcloud', 'caret', 'boot', 'pacman','skimr')

install.lib <- load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib)
sapply(load.lib, require, character = TRUE)

print("Librerías cargadas correctamente")

```

# Problem Set 1: Predicting Income

## Introduction

In the public sector, accurate reporting of individual income is
critical for computing taxes. However, tax fraud of all kinds has always
been a significant issue. According to the Internal Revenue Service
(IRS), about 83.6% of taxes are paid voluntarily and on time in the
US.1. One of the causes of this gap is the under-reporting of incomes by
individuals. An income predicting model could potentially assist in
flagging cases of fraud that could lead to the reduction of the gap.
Furthermore, an income prediction model can help identify vulnerable
individuals and families that may need further assistance.

The objective of the problem set is to apply the concepts we learned
using “real” world data. For that, we are going to scrape from the
following website:
<https://ignaciomsarmiento.github.io/GEIH2018-sample/> This website
contains data for Bogotá from the 2018 “Medición de Pobreza Monetaria y
Desigualdad Report” that takes information from the
[GEIH.](https://www.dane.gov.co/index.php/estadisticas-por-tema/mercado-laboral/empleo-y-desempleo/geih-historicos)

### General Instructions

The main objective is to construct a model of individual hourly wages

$$w = f(X)+u$$

where $w$ is the hourly wage, and $X$ is a matrix that includes
potential explanatory variables/predictors. In this problem set, we will
focus on $f(X) = X\beta$. The final document, in .pdf format, must
contain the following sections:

1.*Introduction.* The introduction briefly states the problem and if
there are any antecedents. It briefly describes the data and its
suitability to address the problem set question. It contains a preview
of the results and main takeaways.

2.*Data.* We will use data for Bogot´a from the 2018 “Medición de
Pobreza Monetaria y Desigualdad Report” that takes information from the
GEIH.

The data set contains all individuals sampled in Bogota and is available
at the following website
<https://ignaciomsarmiento.github.io/GEIH2018-sample/>. To obtain the
data, you must scrape the website.

In this problem set, we will focus only on employed individuals older
than eighteen (18) years old. Restrict the data to these individuals and
perform a descriptive analysis of the variables used in the problem set.
Keep in mind that in the data, there are many observations with missing
data or 0 wages. I leave it to you to find a way to handle this data

When writing this section up, you must:

(a) Describe the data briefly, including its purpose, and any other
    relevant information.

(b) Describe the process of acquiring the data and if there are any
    restrictions to accessing/scraping these data.

(c) Describe the data cleaning process and

(d) Descriptive the variables included in your analysis. At a minimum,
    you should include a descriptive statistics table with its
    interpretation. However, I expect a deep analysis that helps the
    reader understand the data, its variation, and the justification for
    your data choices. Use your professional knowledge to add value to
    this section. Do not present it as a “dry” list of ingredients.

```{r}
# Web Scraping de el dataset-GEIH 2018 proporcionados por el profesor Ignacio Sarmiento
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
pagina <- read_html(paste0(url_base, "1.html"))
datos_totales <- pagina %>% html_table(fill = TRUE) %>% .[[1]]

for (i in 2:10) {
  url <- paste0(url_base, i, ".html")
  tryCatch({
    pagina <- read_html(url)
    tabla <- pagina %>% html_table(fill = TRUE) %>% .[[1]]
    datos_totales <- bind_rows(datos_totales, tabla)
  }, error = function(e) {
    message(paste("Error al cargar la página", i, ":", e))
  })
}

head(datos_totales)

#Guardar el dataset "scrapeado"
datos_totales <- write.csv(datos_totales, "datos_totales.csv")

# Importar el dataset-GEIH 2018
datos_totales <- read_csv("datos_totales.csv")

```

```{r}
# Renombrar columnas y limpiar Datos
datos_totales <- datos_totales %>%
  rename(ingreso_total = ingtot,
         edad = age,
         hombre = sex,
         escolaridad = maxEducLevel,
         cuentapropia = cuentaPropia,
         t_horas_trabajadas = totalHoursWorked,
         salario_hora = y_salary_m_hu) %>%
  mutate(ln_salario_hora = log(salario_hora))

# Filtrar registros inválidos 
datos_filtrados <- datos_totales %>%
  filter(edad > 18, ingreso_total > 0, t_horas_trabajadas > 0, 
        salario_hora > 0)

# Identificar y eliminar outliers usando percentiles 1% y 99%
low_hours <- quantile(datos_filtrados$t_horas_trabajadas, 0.01)
up_hours <- quantile(datos_filtrados$t_horas_trabajadas, 0.99)
low_salary <- quantile(datos_filtrados$salario_hora, 0.01)
up_salary <- quantile(datos_filtrados$salario_hora, 0.99)

datos_filtrados <- datos_filtrados %>%
  filter(t_horas_trabajadas >= low_hours & t_horas_trabajadas <= up_hours,
         salario_hora >= low_salary & salario_hora <= up_salary)

# Codificación de variables de interés
datos_filtrados <- datos_filtrados %>% 
  mutate(jefe = case_when(p6050 == "1" ~ 1,
                          TRUE ~ 0),
         mujer = case_when(hombre == "1" ~ 0,
                           TRUE ~ 1))


# Seleccionar unicamente la variable de Salario Hora, no ingresos
numericas <- datos_filtrados %>% select(-all_of(c("y_ingLab_m_ha", "y_total_m_ha", "p6500", "y_salary_m", 
                                                  "impa", "y_ingLab_m", "y_total_m", "ingtotob", "ingreso_total")))

# Seleccionar las columnas numéricas del dataframe
numericas <- numericas[, sapply(numericas, is.numeric)]

# Filtrar las columnas con desviación estándar diferente a cero y sin valores NA
numericas_filtradas <- numericas[, sapply(numericas, function(x) {
  !all(is.na(x)) && sd(x, na.rm = TRUE) != 0
})]

# Ver el resumen de las columnas filtradas
summary(numericas_filtradas)

# Calcular la correlación de cada variable con 'ingreso_total'
correlaciones_con_y <- sapply(numericas_filtradas, function(x) cor(x, numericas$salario_hora, use = "complete.obs"))

# Crear el dataframe con las correlaciones
resultados_correlacion <- data.frame(Variable = names(correlaciones_con_y), Correlacion_con_y = correlaciones_con_y)

# Mostrar los resultados
print(resultados_correlacion)

# Compute the absolute value of the correlations with 'Salario_hora'
correlaciones_abs <- abs(correlaciones_con_y)

# Sort the correlations in descending order
correlaciones_abs_sorted <- sort(correlaciones_abs, decreasing = TRUE)
print(correlaciones_abs_sorted)

# Select the names of the top 25 variables with the highest correlation
top_25_vars <- names(correlaciones_abs_sorted)[1:25]

# Create a new dataframe with the top 25 variables and their corresponding correlations
top_25_correlaciones <- data.frame(Variable = top_25_vars,
                                   Correlacion_con_y = correlaciones_abs_sorted[1:25])

# Print the results
print(top_25_correlaciones)




# Seleccionar variables importantes para el modelo 

variables_seleccionadas <- c("edad", "clase", "hombre","mujer","college", "depto", "escolaridad", "ocu", "dsi", "informal", "formal", "cuentapropia", "microEmpresa", "salario_hora", "ingtotes", "impa", "isa", "p6500", "p6510", "p6580", "p6750", "p7070", "cotPension", "p6920", "hoursWorkUsual", "hoursWorkActualSecondJob", "fex_c", "fweight", "oficio", "estrato1", "ln_salario_hora", "jefe")

base_seleccionada <- datos_filtrados %>% select(all_of(variables_seleccionadas))

skim(base_seleccionada) 

miss_values <- skim(base_seleccionada) %>% select( skim_variable, n_missing)
Nobs <- nrow(base_seleccionada) 
# percentage of missing
miss_values <- miss_values %>% mutate(p_missing= n_missing/Nobs)
miss_values <- miss_values %>% arrange(-n_missing)

ggplot(miss_values, aes(x = reorder(skim_variable, +p_missing) , y =  p_missing)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  coord_flip() +
  labs(title = "N Missing Per Variable", x = "Var Name", y = "Missings")+ 
  theme(axis.text = element_text(size = 5)) 

# Borrar aquellas variables con más del 90% de missing values ya que imputarlas puede traer más ruido que otra cosa
var_miss <- miss_values %>% filter (p_missing > 0.9)
base_seleccionada <- base_seleccionada %>% select(-all_of(var_miss[[1]]))

# Loop through each column and display descriptive statistics
for (col_name in colnames(base_seleccionada)) {
  cat("Descriptive statistics for", col_name, ":\n")
  print(summary(base_seleccionada[[col_name]]))
  skim(base_seleccionada[[col_name]])
  cat("\n")
}

#Usar cut para crear los grupos de edad
base_seleccionada$grupo_edad <- cut(base_seleccionada$edad, 
                                    breaks = c(-Inf, 20, 30, 40, 50, 60, 70, Inf), 
                                    labels = c("<20", "20-30", "30-40", "40-50", "50-60", 
                                               "60-70", ">70"),
                                    right = FALSE)

base_seleccionada$hombre <- as.factor(base_seleccionada$hombre)



```

```{r}
#Calcular el promedio de ingresos por grupo de edad y género
promedio_ingresos <- base_seleccionada %>%
  group_by(grupo_edad, hombre, escolaridad, oficio, estrato1) %>%
  summarise(promedio = mean(salario_hora, na.rm = TRUE))

ggplot(promedio_ingresos, aes(x = grupo_edad, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Grupo de Edad", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = estrato1, y = promedio)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Estrato", y = "Promedio de Ingresos") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = escolaridad, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Nivel de Educación", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(promedio_ingresos, aes(x = oficio, y = promedio, fill = hombre)) +
  geom_bar(stat = "identity", position = "dodge") +  # position = "dodge" coloca las barras al lado
  labs(x = "Oficio", y = "Promedio de Ingresos", fill = "Hombre") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


## Dispersión Horas Trabajadas
ggplot(data = base_seleccionada , 
       mapping = aes(x = hoursWorkUsual , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Oficio
ggplot(data = base_seleccionada , 
       mapping = aes(x = oficio , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

## Dispersión Estrato
ggplot(data = base_seleccionada , 
       mapping = aes(x = estrato1 , y = salario_hora , group=as.factor(formal) , color=as.factor(formal))) +
  geom_point()

box_plot <- ggplot(data=promedio_ingresos , mapping = aes(as.factor(estrato1) , promedio)) + 
  geom_boxplot() 
box_plot

```

# Punto 3

# *Age-wage profile.*

A great deal of evidence in *labor economics* suggests that the typical
worker’s age-wage profile has a predictable path: *“Wages tend to be low
when the worker is young; they rise as the worker ages, peaking at about
age 50; and the wage rate tends to remain stable or decline slightly
after age 50”.*

In this subsection we are going to estimate the Age-wage profile profile
for the individuals in this sample:

$$log(w) = \beta_{1} + \beta_{2}Age + \beta_{3} Age^{2} + u$$ When
presenting and discussing your results, include:

-   A regression table.
-   An interpretation of the coefficients and it’s significance.
-   A discussion of the model’s in sample fit.
-   A plot of the estimated age-earnings profile implied by the above
    equation. Including a discussion of the “peak age” with it’s
    respective confidence intervals. (Note: Use bootstrap to construct
    the confidence intervals.)

```{r}
#1. Create age_squared
base_seleccionada$edad_squared <- base_seleccionada$edad^2

#2. Regression Analysis
model <- lm(ln_salario_hora ~ edad + edad_squared, data = base_seleccionada)

#3. Regression Table and Interpretation
summary(model)

#4. salida de la regresión
stargazer(model, type = "text")


age_range <- seq(min(base_seleccionada$edad), max(base_seleccionada$edad), length.out = 100)
age_squared_range <- age_range^2
predicted_ln_wage <- predict(model, newdata = data.frame(edad = age_range, edad_squared = age_squared_range))
predicted_wage <- exp(predicted_ln_wage) # Convert log(wage) back to wage

plot(age_range, predicted_wage, type = "l", xlab = "Age (edad)", ylab = "Predicted Hourly Wage", main = "Estimated Age-Earnings Profile")
grid()

#6. Peak Age and Confidence Intervals (Bootstrap)
peak_age <- -coef(model)["edad"] / (2 * coef(model)["edad_squared"])
print(paste("Peak Age:", round(peak_age, 2)))
```

```{r}
n_bootstraps <- 1000
boot_peak_ages <- replicate(n_bootstraps, {
  boot_data <- base_seleccionada[sample(nrow(base_seleccionada), replace = TRUE), ]
  boot_model <- lm(ln_salario_hora ~ edad + edad_squared, data = boot_data)
  -coef(boot_model)["edad"] / (2 * coef(boot_model)["edad_squared"])
})

lower_ci <- quantile(boot_peak_ages, 0.025)
upper_ci <- quantile(boot_peak_ages, 0.975)
print(paste("95% Confidence Interval for Peak Age:", paste("(", round(lower_ci, 2), ",", round(upper_ci, 2), ")")))

```

- Regression table

```{r}
# Estimación del modelo salarial
model <- lm(ln_salario_hora ~ edad + edad_squared, data = base_seleccionada)
# Resumen del modelo estimado
summary(model)

# Salida del modelo de regresión
stargazer(model, type = "text")
```

- Interpretation

$\beta_{1}$ $Intercept$. Represents the baseline value of log(wage) when Age is 0.
$\beta_{2}$ $Age$ Coefficient. Represents the change in log(wage) for each additional year of age.
$\beta_{3}$ $Age^{2}$ Coefficient. Captures the non-linear effect of age on wages, accounting for the curvilinear relationship.

- Discussion

Realizamos una regresión lineal para analizar la relación entre la edad y el salario por hora, utilizando el logaritmo del salario para interpretar los coeficientes como porcentajes. Los resultados indican que la edad tiene un efecto estadísticamente significativo en el salario. Por cada año adicional, el salario tiende a aumentar, lo que se refleja en el coeficiente positivo de la variable "edad". Sin embargo, al incluir la edad al cuadrado, observamos que este efecto positivo disminuye a medida que la edad avanza, sugiriendo una posible estabilización o incluso disminución del salario en edades más avanzadas. A pesar de la significancia estadística de la edad y la edad al cuadrado, el modelo en su conjunto no explica una gran proporción de la variación en el salario por hora. El R-cuadrado, que mide la bondad de ajuste del modelo, es bastante bajo, alrededor del 3.5%. Esto significa que nuestro modelo solo captura una pequeña parte de las diferencias salariales observadas, lo que sugiere que hay otros factores importantes que influyen en el salario y que no estamos considerando. En conclusión, aunque la edad es un factor relevante en la determinación del salario, nuestro modelo indica que no es el único ni el más importante. El bajo ajuste del modelo sugiere que factores como la educación, la experiencia laboral o el sector de empleo podrían tener un impacto significativo en el salario por hora. Por lo tanto, aunque la edad proporciona información valiosa, se necesita un análisis más completo para entender completamente la dinámica salarial.

- plot of the estimated age-earning










  

# Punto 4

# *The gender earnings GAP*

Policymakers have long been concerned with the gender wage gap, and is
going to be our focus in this subsection.

<!-- -->

(a) Begin by estimating and discussing the unconditional wage gap:

$$log(w) = \beta_{1} + \beta_{2}Female + u$$ where *Female* is an
indicator that takes one if the individual in the sample is identified
as female.

(b) *Equal Pay for Equal Work?* A common slogan is“equal pay for equal
    work”. One way to interpret this is that for employees with similar
    worker and job characteristics, no gender wage gap should exist.
    Estimate a conditional earnings gap incorporating control variables
    such as similar worker and job characteristics. In this section,
    estimate the conditional wage gap:

-   First, using FWL
-   Second, using FWL with bootstrap. Compare the estimates and the
    standard errors.

(c) Next, plot the predicted age-wage profile and estimate the implied
    “peak ages” with the respective confidence intervals by gender

When presenting and discussing your results, include:

-   An estimating equation, explaining the included control variables
    *(beware of “bad controls”).*
-   A regression table, with the estimates side by side of the
    conditional and unconditional wage gaps, highlighting the
    coefficient of interest. Controls, should not be included in the
    table but dutifully noted.
-   An interpretation of the“Female” coefficients, a comparison between
    the models, and the in-sample fit.
-   A discussion about the implied peak ages and their statistical
    similarity/difference.
-   A thoughtful discussion about the unconditional and conditional wage
    gap, seeking to answer if the changes in the coefficient are
    evidence of a selection problem, a ”discrimination problem,” a mix,
    or none of these issues.


Las variables de control son escolaridad, edad, $edad^{2}$, cuentapropia, jefe de hogar, formal y ocupado. Las variables explicativas que pueden ser malos controles, son formal, ocupado o cuentapropista, la explicaci\'on se debe a que estas variables pueden estar correlacionas entre ellas, al igual que con la variable predictora (logaritmo de salarios), es el caso de ser formal, esta posiblemente est\'e fuertemente relacionada con la variable dependiente, o lo que es lo mismo presentar problemas de endogeneidad (econometr\'ia cl\'asica).

*Interpretaciónn de los coeficientes:*

Para el modelo de brecha salarial incondicional, observamos que el coeficiente es de -0.028 y es estadisticamente significativo al 95\% de confianza. Este quiere decir que la mujer gana en promedio 2.8 pesos menos con respecto al hombre, por lo que la brecha salarial es considerable. Si se incluyen las variables de control, este valor se incrementa y llega a -0.067 es estadisticamente significativo al 99\% de confianza. En este caso, la brecha se incrementa un poco y ahora la mujer gana en promedio 6.7 menos pesos que el hombre evidenciando así la discriminaci\'on en el mercado de trabajo.



```{r}
# Modelo incondicional
modelo_incondicional <- lm(ln_salario_hora ~ mujer, data = base_seleccionada)
summary(modelo_incondicional)
stargazer(modelo_incondicional, type = "text")
```

```{r}
# Variables de control, modelo condicional
controles <- lm(ln_salario_hora ~ mujer + escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = base_seleccionada)
summary(controles)
stargazer(controles, type = "text")
residuos_salario <- residuals(controles)

controles_genero <- lm(mujer ~ escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = base_seleccionada)
residuos_genero <- residuals(controles_genero)

# Modelo FWL
modelo_fwl <- lm(residuos_salario ~ residuos_genero)
summary(modelo_fwl)
stargazer(modelo_fwl, type = "text")
```

```{r}
# Bootstrap para FWL
fwl_bootstrap <- function(data, indices) {
  datos_boot <- data[indices, ]
  controles <- lm(ln_salario_hora ~ mujer + escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = datos_boot)
  residuos_salario <- residuals(controles)
  
  controles_genero <- lm(mujer ~ escolaridad + edad + I(edad^2) + cuentapropia + jefe + formal + ocu, data = datos_boot)
  residuos_genero <- residuals(controles_genero)
  
  modelo <- lm(residuos_salario ~ residuos_genero)
  coef(modelo)[2] # Devuelve el coeficiente para "residuos_genero"
}

# Aplicar bootstrap
resultados_bootstrap <- boot(data = base_seleccionada, statistic = fwl_bootstrap, R = 1000)
summary(resultados_bootstrap)
```

```{r}
stargazer(modelo_incondicional, controles, type = "text", omit = c("escolaridad", "edad", "cuentapropia", "jefe", "formal", "I(edad2)", "ocu"))

```

```{r}
# Modelo polinómico para edad
modelo_edad <- lm(ln_salario_hora ~ edad + I(edad^2) + mujer, data = base_seleccionada)
summary(modelo_edad)
stargazer(modelo_edad, type = "text")

# Edad "punta"
edad_punta <- -coef(modelo_edad)["Edad"] / (2 * coef(modelo_edad)["I(Edad^2)"])
intervalo_confianza <- confint(modelo_edad)

# Gráfico edad-salario
ggplot(base_seleccionada, aes(x = edad, y = ln_salario_hora, color = mujer)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = TRUE) +
  labs(title = "Perfil Edad-Salario", x = "Edad", y = "Salario")
```

# Punto 5

# *Predicting earnings*

In the previous sections, you estimated some specifications with
inference in mind. In this subsection, we will evaluate the predictive
power of these specifications.

(a) Split the sample into two: a training (70%) and a testing (30%)
    sample. (Don’t forget to set a seed to achieve reproducibility. In
    R, for example you can use set.seed(10101), where 10101 is the
    seed.)

(b) Report and compare the predictive performance in terms of the RMSE
    of all the previous specifications with at least five (5) additional
    specifications that explore non-linearities and complexity.

(c) In your discussion of the results, comment:

-   About the overall performance of the models.
-   About the specification with the lowest prediction error.
-   For the specification with the lowest prediction error, explore
    those observations that seem to ”miss the mark.” To do so, compute
    the prediction errors in the test sample, and examine its
    distribution. Are there any observations in the tails of the
    prediction error distribution? Are these outliers potential people
    that the DIAN should look into, or are they just the product of a
    flawed model?

(d) LOOCV. For the two models with the lowest predictive error in the
    previous section, calculate the predictive error using
    Leave-one-out-cross-validation (LOOCV). Compare the results of the
    test error with those obtained with the validation set approach and
    explore the potential links with the influence statistic. (Note:
    when attempting this subsection, the calculati

#5.A

```{r}
set.seed(10101)
base_seleccionada$id <- 1:nrow(base_seleccionada)
datos_entrenamiento <- base_seleccionada %>% sample_frac(0.7)
datos_prueba <- base_seleccionada %>% anti_join(datos_entrenamiento, by = "id")

cat("Tamaño del conjunto de entrenamiento:", nrow(datos_entrenamiento), "\n")
cat("Tamaño del conjunto de prueba:", nrow(datos_prueba), "\n")

```

#5B

```{r}
# Modelos de Regresión

## Modelo 1: 

modelo1 <- lm(ln_salario_hora ~ edad + I(edad^2), data = datos_entrenamiento)
summary(modelo1)

## Modelo 2: 

modelo2 <- lm(ln_salario_hora ~ mujer + edad, data = datos_entrenamiento)
summary(modelo2)

stargazer(modelo1, modelo2, type = "latex")

```

```{r}
# Modelos adicionales para Modelo 1
modelo1_1 <- lm(ln_salario_hora ~ edad + I(edad^2) + I(edad^3), data = datos_entrenamiento)
modelo1_2 <- lm(ln_salario_hora ~ edad + I(edad^2) + mujer, data = datos_entrenamiento)
modelo1_3 <- lm(ln_salario_hora ~ edad * I(edad^2), data = datos_entrenamiento)
modelo1_4 <- lm(ln_salario_hora ~ poly(edad, 3), data = datos_entrenamiento)
modelo1_5 <- lm(ln_salario_hora ~ edad + I(edad^2) + edad:mujer, data = datos_entrenamiento)

stargazer(modelo1_1, modelo1_2, modelo1_3, modelo1_4, modelo1_5, type = "latex")

# Modelos adicionales para Modelo 2
modelo2_1 <- lm(ln_salario_hora ~ mujer + edad + I(edad^2), data = datos_entrenamiento)
modelo2_2 <- lm(ln_salario_hora ~ mujer * edad, data = datos_entrenamiento)
modelo2_3 <- lm(ln_salario_hora ~ mujer + poly(edad, 3), data = datos_entrenamiento)
modelo2_4 <- lm(ln_salario_hora ~ mujer + edad + I(edad^2) + edad:mujer, data = datos_entrenamiento)
modelo2_5 <- lm(ln_salario_hora ~ mujer + poly(edad, 4), data = datos_entrenamiento)


stargazer(modelo2_1, modelo2_2, modelo2_3, modelo2_4, modelo2_5, type = "latex")

```

```{r}
# Función para calcular el RMSE
calcular_rmse <- function(modelo, datos_prueba) {
  predicciones <- predict(modelo, newdata = datos_prueba)
  sqrt(mean((datos_prueba$ln_salario_hora - predicciones)^2))
}

# Lista de modelos
modelos <- list(
  "Modelo 1" = modelo1, "Modelo 1.1" = modelo1_1, "Modelo 1.2" = modelo1_2,
  "Modelo 1.3" = modelo1_3, "Modelo 1.4" = modelo1_4, "Modelo 1.5" = modelo1_5,
  "Modelo 2" = modelo2, "Modelo 2.1" = modelo2_1, "Modelo 2.2" = modelo2_2,
  "Modelo 2.3" = modelo2_3, "Modelo 2.4" = modelo2_4, "Modelo 2.5" = modelo2_5
)

# Calcular RMSE
resultados_rmse <- lapply(modelos, calcular_rmse, datos_prueba = datos_prueba)

# Convertir a data frame ordenado
rmse_df <- data.frame(
  Modelo = names(resultados_rmse),
  RMSE = unlist(resultados_rmse)
) %>% arrange(RMSE)

# Tabla de RMSE

cat("\nComparación de RMSE entre Modelos\n")
cat("=================================\n")
cat(sprintf("%-20s %10s\n", "Modelo", "RMSE"))
cat("---------------------------------\n")
for (i in 1:nrow(rmse_df)) {
  cat(sprintf("%-20s %10.3f\n", rmse_df$Modelo[i], rmse_df$RMSE[i]))
}
cat("---------------------------------\n")


```

#5C

```{r}
# Seleccionar el modelo con el menor RMSE
mejor_modelo <- modelo2_5

# Predecir valores y calcular errores en el set de prueba
datos_prueba$predicciones <- predict(mejor_modelo, newdata = datos_prueba)
datos_prueba$error <- datos_prueba$ln_salario_hora - datos_prueba$predicciones

# Visualizar la distribución de los errores
library(ggplot2)
ggplot(datos_prueba, aes(x = error)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Distribución de Errores de Predicción", x = "Error", y = "Frecuencia")

# Identificar outliers (percentiles 1% y 99%)
percentiles <- quantile(datos_prueba$error, probs = c(0.01, 0.99))
outliers <- datos_prueba %>%
  filter(error < percentiles[1] | error > percentiles[2])

# Mostrar las observaciones atípicas (outliers)
print(outliers)

# Resumen de los errores
summary(datos_prueba$error)

# Visualizar outliers con un gráfico
ggplot(outliers, aes(x = edad, y = ln_salario_hora, color = mujer)) +
  geom_point(size = 3) +
  labs(title = "Outliers: Edad vs Salario (log)", x = "Edad", y = "ln(Salario por hora)")
```

i.  Desempeño de los modelos: En general, los modelos presentan un
    desempeño relativamente bueno, con RMSE que oscilan entre 0.626 y
    0.634. Dado que ahora solo usamos las variables edad y género
    (mujer), la capacidad predictiva ha sido más conservadora en
    comparación con los modelos anteriores, lo que sugiere que la
    eliminación de variables como escolaridad ha reducido la complejidad
    del modelo, pero también su precisión.

ii. Modelos con mejor desempeño: El modelo con el menor RMSE es el
    Modelo 2.5 (0.626), seguido muy de cerca por el Modelo 2.3 (0.627).
    Estos modelos incluyen combinaciones no lineales de edad (como su
    cuadrado) e interacciones con género. Esto reafirma que, aunque las
    variables predictivas son limitadas, la inclusión de términos no
    lineales sigue aportando valor, al capturar relaciones complejas
    entre edad y salario.

iii. Distribución de errores: La distribución de los errores de
     predicción muestra una forma aproximadamente normal, con una fuerte
     concentración alrededor de 0. Esto indica que, en general, los
     modelos tienden a predecir los salarios con una precisión
     razonable, sin sesgo sistemático claro.

iv. Asimetría positiva: Hay una asimetría positiva evidente, con valores
    más alejados hacia la derecha. Esto sugiere que algunos salarios
    fueron significativamente subestimados por los modelos, lo cual
    podría reflejar que existen individuos con ingresos muy altos que
    las variables edad y género no logran explicar adecuadamente.

v.  Outliers: El análisis de outliers (percentiles 1% y 99%) revela que
    hay observaciones extremas con errores considerables. Estos outliers
    podrían estar relacionados con personas que reciben salarios
    inusualmente bajos o altos, potencialmente debido a factores no
    contemplados por los modelos, como la ocupación, el nivel educativo
    o experiencia laboral.

vi. Reflexión sobre observaciones extremas: Aunque no se puede afirmar
    con certeza si estas observaciones extremas representan errores en
    la recolección de datos o casos legítimos que escapan a las
    capacidades explicativas de los modelos, queda claro que hay
    limitaciones al usar solo edad y género. Para mejorar las
    predicciones, sería útil explorar modelos más complejos que incluyan
    otras variables relevantes o considerar técnicas más robustas para
    mitigar la influencia de outliers.

#5D

```{r}
ctrl <- trainControl(method = "LOOCV")

# Modelo 2.5
modelo_2_5 <- train(ln_salario_hora ~ edad * mujer + I(edad^2), 
                    data = base_seleccionada, 
                    method = "lm", 
                    trControl = ctrl)

# Modelo 2.3
modelo_2_3 <- train(ln_salario_hora ~ edad + mujer + I(edad^2), 
                    data = base_seleccionada, 
                    method = "lm", 
                    trControl = ctrl)

# RMSE de cada modelo (LOOCV)
rmse_loocv_2_5 <- modelo_2_5$results$RMSE
rmse_loocv_2_3 <- modelo_2_3$results$RMSE

# Resultados
cat("RMSE LOOCV para el Modelo 2.5:", rmse_loocv_2_5, "\n")
cat("RMSE LOOCV para el Modelo 2.3:", rmse_loocv_2_3, "\n")
```

Tras el análisis realizado, se obtuvieron los siguientes resultados en
cuanto al desempeño predictivo de los modelos estimados:

Desempeño en el conjunto de validación:

El Modelo 2.5 presentó el menor RMSE, con un valor de 0.626.

El Modelo 2.3 le siguió de cerca, con un RMSE de 0.627.

Desempeño con validación cruzada (LOOCV):

El RMSE LOOCV para el Modelo 2.5 fue de 0.6331.

El RMSE LOOCV para el Modelo 2.3 fue de 0.6340.

Ambos modelos incluyen combinaciones no lineales de la variable edad,
como su término cuadrático, y consideran las interacciones con el género
(mujer), lo que permite capturar relaciones complejas entre estas
variables y el salario por hora.

A pesar de que el Modelo 2.5 obtuvo el menor RMSE tanto en validación
como en LOOCV, la diferencia con el Modelo 2.3 es marginal. Esto sugiere
que ambos modelos tienen un desempeño muy similar y que las mejoras
adicionales logradas por el Modelo 2.5 son leves, aunque consistentes.

El hecho de que las puntuaciones de RMSE en validación y LOOCV no
difieran significativamente indica que los modelos no están
sobreajustados y que su capacidad predictiva es relativamente estable al
enfrentarse a nuevos datos.

Sin embargo, es importante destacar que, dado que solo se utilizaron las
variables edad y género, las predicciones aún presentan limitaciones. La
presencia de outliers y la asimetría positiva en los errores sugieren
que hay factores adicionales —como la escolaridad, la ocupación o la
experiencia laboral— que no fueron considerados y que podrían ayudar a
mejorar el poder explicativo de los modelos.

En conclusión, el Modelo 2.5 se posiciona como el mejor modelo
predictivo dentro de los estimados, aunque el Modelo 2.3 ofrece
resultados muy similares. Para futuras investigaciones, se recomienda
explorar la inclusión de nuevas variables y el uso de técnicas más
avanzadas para robustecer las predicciones.
