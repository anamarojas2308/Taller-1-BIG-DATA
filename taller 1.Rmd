---
title: "Primer Taller big data"
authors: "Julian Delgado Gutierrez, Ana María Rojas, Juan David Rincón, Mario"
date: "2025-02-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Configuración Inicial
```{r setup, include=FALSE}
rm(list = ls())
gc()
closeAllConnections()

# Cargar librerías necesarias
load.lib <- c('data.table', 'dplyr', 'ggplot2', 'stargazer', 'tidyverse', 'lubridate',
              'plotly', 'rvest', 'tm', 'wordcloud', 'caret', 'boot', 'pacman')

install.lib <- load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib)
sapply(load.lib, require, character = TRUE)

print("Librerías cargadas correctamente")
```
PUNTO 2:
# Web Scraping de GEIH
```{r scraping, include=FALSE}
url_base <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_"
pagina <- read_html(paste0(url_base, "1.html"))
datos_totales <- pagina %>% html_table(fill = TRUE) %>% .[[1]]

for (i in 2:10) {
  url <- paste0(url_base, i, ".html")
  tryCatch({
    pagina <- read_html(url)
    tabla <- pagina %>% html_table(fill = TRUE) %>% .[[1]]
    datos_totales <- bind_rows(datos_totales, tabla)
  }, error = function(e) {
    message(paste("Error al cargar la página", i, ":", e))
  })
}

head(datos_totales)
```
#PUNTO 2A:
#Describir brevemente la data:
#Una vez se combinan los datos y se obtiene la base completa, se evidencia que hay información que nos permite analizar el mercado laboral y variables ecónomicas de diferentes individios. Se encuentra que el objetivo principal de la base de datos es analizar ingresos (salario) y comportamientos del mercado. Hay variables que nos permiten analizar características individuales como la edad, género, educación, departamento, entre otras y variables que se relacionan con la actividad laboral como los ingresos, horas trabajadas, tipo de empleo, sector económico, entre otras. La selección de las variables es clave puesto que permitirá evaluar los factores que influyen en el ingreso y analizar fenómenos como la brecha salarial de género. De igual forma, es importante mencionar que la base tiene valores faltantes y observaciones con ingreso igual a cero, lo que sugiere la necesidad de un proceso de limpieza antes del análisis. La base tiene una estructura de formato tabular, la cual facilita el procesamiento de los datos y el análisis de los mismos mediante descripciones estadísticas. Adicionalmente, se considera que los datos proporcionados son fundamentales para construir un modelo predictivo de ingresos por hora y detectar como variables sociodemográficas y laborales inciden en la remuneración de los individuos.

#PUNTO 2B:
#Proceso y dificultades accediendo a la data:
#En primer lugar hay que tener presente que los datos no se pueden descargar como un archivo, sino que se encuentran en un página web (https://ignaciomsarmiento.github.io/GEIH2018_sample/), por lo cual, es necesario hacer web scrapping para extraerlos. Los datos estaban distribuidos en diferentes sitios web, por lo se combinaron en un único conjunto de datos. De esta forma, se difinió la base de la URL, donde cada página se nombró siguiendo un patrón (geih_page_1.html", "geih_page_2.html ..., etc). Con ayuda de la libreria rvest se leyó el contenido HTML de cada página (data chunk 1:10), se extrajeron las tablas y se combinaron los datos en un solo dataframe, almacenando el resultado en la variables datos_totales. Para evitar que el código fuese a generar error en caso de que una de las páginas no cargara correctamente, se utilizó tryCatch (manejo de errores). De esta forma, se buscaba que si las páginas cargaban correctamente, se extrayera las tablas y se añadieran a la variable "datos_totales" y si se llegaba a presentar algún problema de lectura, se captaría el error sin detener la ejecución total. Por lo tanto, el código permite automatizar el proceso de recolección de datos que están distribuidores en diferentes sitios web y cuando se trabaja con grandes volúmenes de datos, aún si se presenta algún problema. No se encuentran restricciones dado que la página no tiene capchas ni bloqueos para la extracción de datos, pero tuvimos presente no hacer múltiples solicitudes en un corto período de tiempo para no sobrecargar el servidor. Por el otro lado, los datos son públicos y fueron diseñados para fines académicos, por lo que facilito en gran medida el scrapping. 

# Renombrar Columnas y Limpiar Datos
```{r limpieza, include=FALSE}
datos_totales <- datos_totales %>%
  rename(
    ingreso_total = ingtot,
    edad = age,
    hombre = sex,
    T_horas_trabajadas = totalHoursWorked,
    Salario_hora = y_salary_m_hu
  ) %>%
  mutate(
    ln_Salario_hora = log(Salario_hora)
  )

# Filtrar registros inválidos

datos_filtrados <- datos_totales %>%
  filter(edad >= 18, ingreso_total > 0, T_horas_trabajadas > 0, Salario_hora > 0)

# Identificar y eliminar outliers usando percentiles 1% y 99%
low_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.01)
up_hours <- quantile(datos_filtrados$T_horas_trabajadas, 0.99)
low_salary <- quantile(datos_filtrados$Salario_hora, 0.01)
up_salary <- quantile(datos_filtrados$Salario_hora, 0.99)

datos_filtrados <- datos_filtrados %>%
  filter(T_horas_trabajadas >= low_hours & T_horas_trabajadas <= up_hours,
         Salario_hora >= low_salary & Salario_hora <= up_salary)

```
COMPLEMENTO JUAN:



# Dividir Datos en Entrenamiento y Prueba
```{r dividir_datos, include=FALSE}
set.seed(10101)
datos_filtrados$id <- 1:nrow(datos_filtrados)
datos_entrenamiento <- datos_filtrados %>% sample_frac(0.7)
datos_prueba <- datos_filtrados %>% anti_join(datos_entrenamiento, by = "id")

cat("Tamaño del conjunto de entrenamiento:", nrow(datos_entrenamiento), "\n")
cat("Tamaño del conjunto de prueba:", nrow(datos_prueba), "\n")
```
# Modelos de Regresión

## Modelo 1: Constante
```{r modelo1, include=FALSE}
modelo1 <- lm(ln_Salario_hora ~ 1, data = datos_entrenamiento)
summary(modelo1)
```

## Modelo 2: Edad y Edad^2
```{r modelo2, include=FALSE}
modelo2 <- lm(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento)
summary(modelo2)
```

## Modelo 3: Género y Edad
```{r modelo3, include=FALSE}
modelo3 <- lm(ln_Salario_hora ~ hombre + edad, data = datos_entrenamiento)
summary(modelo3)
```

# Evaluación de Modelos (RMSE)
```{r evaluacion, include=FALSE}
rmse <- function(actual, predicho) {
  sqrt(mean((actual - predicho)^2))
}

datos_prueba$prediccion_m1 <- predict(modelo1, newdata = datos_prueba)
datos_prueba$prediccion_m2 <- predict(modelo2, newdata = datos_prueba)
datos_prueba$prediccion_m3 <- predict(modelo3, newdata = datos_prueba)

rmse_m1 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m1)
rmse_m2 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m2)
rmse_m3 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m3)

cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
```

# Intervalos de Confianza mediante Bootstrap
```{r bootstrap, include=FALSE}
# Función para bootstrap del coeficiente de edad
boot_fn <- function(data, indices) {
  modelo_boot <- lm(ln_Salario_hora ~ edad + I(edad^2), data = data[indices, ])
  return(coef(modelo_boot))
}

boot_results <- boot(datos_entrenamiento, boot_fn, R = 1000)

# Intervalo de confianza al 95% para el coeficiente de edad
boot.ci(boot_results, type = "perc", index = 2)
```

# Visualización de la Curva de Edad-Ingreso
```{r curva_edad_ingreso, include=FALSE}
edad_seq <- data.frame(edad = seq(min(datos_entrenamiento$edad), max(datos_entrenamiento$edad), by = 1))
edad_seq$ln_Salario_hora_pred <- predict(modelo2, newdata = edad_seq)

curv_edad_salario <- ggplot(datos_entrenamiento, aes(x = edad, y = ln_Salario_hora)) +
                      geom_point(alpha = 0.3) +
                      geom_line(data = edad_seq, aes(x = edad, y = ln_Salario_hora_pred), color = "blue") +
                      labs(title = "Curva de Edad vs. Log Salario Hora",
                       x = "Edad", y = "Log Salario Hora")

print(curv_edad_salario)
```

# Comparación entre Modelos Condicionales y No Condicionales
```{r comparacion_modelos, include=FALSE}
modelo_sin_controles <- lm(ln_Salario_hora ~ hombre, data = datos_entrenamiento)
modelo_con_controles <- lm(ln_Salario_hora ~ hombre + edad + T_horas_trabajadas, data = datos_entrenamiento)

stargazer(modelo_sin_controles, modelo_con_controles, type = "text", title = "Comparación de Modelos")
```

# Validación Cruzada (5-fold)
```{r validacion_cruzada, include=FALSE}
train_control <- trainControl(method = "cv", number = 5)
modelo_cv <- train(ln_Salario_hora ~ edad + I(edad^2), data = datos_entrenamiento, method = "lm", trControl = train_control)
print(modelo_cv)
```

# Modelos Adicionales (Polinomiales e Interacciones)
```{r modelos_adicionales, include=FALSE}
modelo4 <- lm(ln_Salario_hora ~ poly(edad, 3, raw = TRUE), data = datos_entrenamiento)
modelo5 <- lm(ln_Salario_hora ~ hombre * edad, data = datos_entrenamiento)
modelo6 <- lm(ln_Salario_hora ~ hombre + edad + I(edad^2) + T_horas_trabajadas, data = datos_entrenamiento)
modelo7 <- lm(ln_Salario_hora ~ poly(edad, 2) + log(T_horas_trabajadas), data = datos_entrenamiento)

# Predicciones y RMSE para los nuevos modelos
datos_prueba$prediccion_m4 <- predict(modelo4, newdata = datos_prueba)
datos_prueba$prediccion_m5 <- predict(modelo5, newdata = datos_prueba)
datos_prueba$prediccion_m6 <- predict(modelo6, newdata = datos_prueba)
datos_prueba$prediccion_m7 <- predict(modelo7, newdata = datos_prueba)

rmse_m4 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m4)
rmse_m5 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m5)
rmse_m6 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m6)
rmse_m7 <- rmse(datos_prueba$ln_Salario_hora, datos_prueba$prediccion_m7)
```

# Mostrar los resultados de RMSE para todos los modelos
```{r resultados_rmse, include=FALSE}
cat("RMSE Modelo 1:", round(rmse_m1, 4), "\n")
cat("RMSE Modelo 2:", round(rmse_m2, 4), "\n")
cat("RMSE Modelo 3:", round(rmse_m3, 4), "\n")
cat("RMSE Modelo 4:", round(rmse_m4, 4), "\n")
cat("RMSE Modelo 5:", round(rmse_m5, 4), "\n")
cat("RMSE Modelo 6:", round(rmse_m6, 4), "\n")
cat("RMSE Modelo 7:", round(rmse_m7, 4), "\n")
```

# Comparación gráfica de los errores de predicción entre los modelos
```{r comparacion_grafica, include=FALSE}
mse_values <- data.frame(
  Modelo = c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5", "Modelo 6", "Modelo 7"),
  RMSE = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6, rmse_m7)
)

# Visualizar los RMSE en un gráfico de barras

RMSE_barras <- ggplot(mse_values, aes(x = Modelo, y = RMSE, fill = Modelo)) +
                 geom_bar(stat = "identity", show.legend = FALSE) +
                 labs(title = "Comparación de RMSE entre Modelos",
                      x = "Modelo", y = "RMSE") +
                 theme_minimal()

print(RMSE_barras)
```
